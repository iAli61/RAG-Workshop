{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8aa4c7",
   "metadata": {},
   "source": [
    "# Demo #9: Agentic RAG with Routing and Tools\n",
    "\n",
    "## Objective\n",
    "Build an autonomous agent that routes queries to appropriate data sources (vector DB, SQL, web search) and orchestrates multi-source information synthesis.\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "### The Paradigm Shift: From Static Pipelines to Autonomous Agents\n",
    "\n",
    "Traditional RAG systems follow a **static, predetermined workflow**: retrieve → augment → generate. This linear approach works well for simple question-answering but falls short when facing queries that require:\n",
    "- Information from **multiple, heterogeneous data sources** (documents, databases, APIs)\n",
    "- **Multi-step reasoning** where intermediate results inform subsequent retrieval decisions\n",
    "- **Dynamic adaptation** based on what is (or isn't) found\n",
    "\n",
    "**Agentic RAG** represents a paradigm shift to a **dynamic, autonomous process** orchestrated by an LLM. The LLM is elevated from a mere text generator to a **reasoning engine** that can:\n",
    "- **Plan**: Decompose complex tasks into logical sub-tasks\n",
    "- **Decide**: Choose which tools or data sources to use\n",
    "- **Execute**: Call external tools via APIs (retrieval systems, databases, web search)\n",
    "- **Observe**: Analyze the results and decide on the next action\n",
    "- **Self-Correct**: Adapt strategy if initial attempts fail\n",
    "\n",
    "This transforms the RAG system from a simple question-answering tool into an **autonomous problem-solver**.\n",
    "\n",
    "### Core Agent Architectures\n",
    "\n",
    "Several distinct agent-based architectural patterns have emerged:\n",
    "\n",
    "#### 1. **Routing Agents**\n",
    "In enterprise scenarios, knowledge is fragmented across multiple sources:\n",
    "- **Vector database** for unstructured documents\n",
    "- **SQL database** for transactional/structured data\n",
    "- **Web search API** for current events\n",
    "- **Knowledge graphs** for entity relationships\n",
    "\n",
    "A **routing agent** acts as an **intelligent dispatcher**. It analyzes the user's query and determines the most appropriate data source or tool to use. This ability to intelligently query and synthesize information from diverse sources is what makes RAG truly viable in complex enterprise environments.\n",
    "\n",
    "#### 2. **ReAct (Reason + Act) Agents**\n",
    "The ReAct framework provides a powerful mechanism for **dynamic, multi-step reasoning**. An agent operating under this framework follows a **\"Reason-Act-Observe\" loop**:\n",
    "\n",
    "1. **Reason**: Analyze the problem and formulate a plan\n",
    "2. **Act**: Take an action (e.g., perform a retrieval, query a database)\n",
    "3. **Observe**: Examine the outcome of that action\n",
    "4. **Repeat**: Use new information to refine reasoning for the next step\n",
    "\n",
    "This iterative process allows the agent to:\n",
    "- Dynamically adjust its strategy\n",
    "- Handle unexpected outcomes\n",
    "- Perform self-correction\n",
    "\n",
    "#### 3. **Plan-and-Execute Agents**\n",
    "As an evolution of ReAct, these agents **separate planning and execution**:\n",
    "1. First construct a complete, multi-step plan\n",
    "2. Then execute the entire plan sequentially\n",
    "\n",
    "This improves efficiency and reduces costs for tasks where the plan is unlikely to change based on intermediate results.\n",
    "\n",
    "### The LLM as Meta-Reasoner\n",
    "\n",
    "In agentic architectures, the LLM plays a **dual role**:\n",
    "1. **Generator**: Still produces the final response\n",
    "2. **Orchestrator**: More importantly, it becomes the control unit for the entire retrieval and reasoning process\n",
    "\n",
    "It performs **meta-reasoning** about the task itself:\n",
    "- \"Is the information I have sufficient?\"\n",
    "- \"Do I need to use a different tool?\"\n",
    "- \"Should I rephrase my query?\"\n",
    "- \"Can I answer this from my parametric knowledge, or do I need external data?\"\n",
    "\n",
    "This self-reflection and strategic planning represent a higher level of intelligence, positioning the LLM as the central \"brain\" for a complex, multi-component AI system.\n",
    "\n",
    "### Multi-Source Data Synthesis Example\n",
    "\n",
    "Consider the query: **\"Compare the market sentiment for our new product with its Q1 sales figures.\"**\n",
    "\n",
    "This cannot be answered by a single retrieval. An agentic system handles this by:\n",
    "1. **Routing agent** identifies the query requires two types of information:\n",
    "   - Sentiment (from web/news data)\n",
    "   - Sales figures (from internal database)\n",
    "2. Agent executes a search against a **web-focused tool** to retrieve articles and social media posts\n",
    "3. Agent concurrently executes a query against a **SQL database tool** to retrieve Q1 sales data\n",
    "4. LLM receives both sets of retrieved context to **synthesize a final answer** integrating both market sentiment and quantitative sales performance\n",
    "\n",
    "## What We'll Demonstrate\n",
    "\n",
    "In this demo, we'll build a **ReAct-based routing agent** that:\n",
    "1. Has access to **three distinct tools**:\n",
    "   - **Document Search Tool**: Queries a vector database of technical documentation\n",
    "   - **Structured Data Tool**: Queries an in-memory \"database\" of structured product information\n",
    "   - **Web Search Tool**: Simulated web search for current information\n",
    "2. **Autonomously decides** which tool(s) to use based on the query\n",
    "3. **Shows its reasoning process** (Reason-Act-Observe traces)\n",
    "4. Can **synthesize information from multiple sources** in a single response\n",
    "\n",
    "We'll compare this with a standard, single-source RAG system to highlight the advantages of agentic architecture.\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- *What is Agentic RAG?* | IBM (Reference 57)\n",
    "- *GraphRAG and Agentic Architecture* - Neo4j (Reference 55)\n",
    "- Curriculum: \"The Autonomous Frontier: Agentic RAG Architectures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a9b5d",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a3c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LlamaIndex core\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Settings\n",
    ")\n",
    "\n",
    "# Azure OpenAI\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# Agent and Tools\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35780b6",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c646f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Azure OpenAI configured\n",
      "  LLM: gpt-4\n",
      "  Embedding: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAI Configuration\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    temperature=0.1  # Low temperature for more deterministic reasoning\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-ada-002\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "# Configure global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "print(\"✓ Azure OpenAI configured\")\n",
    "print(f\"  LLM: {llm.model}\")\n",
    "print(f\"  Embedding: text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c118892",
   "metadata": {},
   "source": [
    "## 3. Multi-Source Data Setup\n",
    "\n",
    "We'll create three distinct data sources to simulate a real enterprise environment:\n",
    "\n",
    "### Source 1: Vector Database (Unstructured Documents)\n",
    "Technical documentation stored in markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6991e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from: data/tech_docs\n",
      "✓ Loaded 6 documents\n",
      "  - bert_model.md\n",
      "  - docker_containers.md\n",
      "  - embeddings_ml.md\n",
      "  - gpt4_model.md\n",
      "  - rest_api.md\n",
      "  - transformer_architecture.md\n"
     ]
    }
   ],
   "source": [
    "# Load technical documentation\n",
    "data_dir = Path(\"./data/tech_docs\")\n",
    "\n",
    "print(f\"Loading documents from: {data_dir}\")\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=str(data_dir),\n",
    "    required_exts=[\".md\"]\n",
    ").load_data()\n",
    "\n",
    "print(f\"✓ Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    filename = Path(doc.metadata['file_path']).name\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index\n",
    "print(\"Building vector index...\")\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Create query engine\n",
    "vector_query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    response_mode=\"compact\"\n",
    ")\n",
    "\n",
    "print(\"✓ Vector index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb59d29",
   "metadata": {},
   "source": [
    "### Source 2: Structured Database (Simulated SQL)\n",
    "Product and sales data in a structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5635b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing structured data query:\n",
      "{\n",
      "  \"sales_q1_2024\": [\n",
      "    {\n",
      "      \"product_id\": \"P001\",\n",
      "      \"units_sold\": 1520,\n",
      "      \"revenue\": 455848.0\n",
      "    },\n",
      "    {\n",
      "      \"product_id\": \"P002\",\n",
      "      \"units_sold\": 890,\n",
      "      \"revenue\": 444991.0...\n",
      "\n",
      "✓ Structured database configured\n"
     ]
    }
   ],
   "source": [
    "# Simulated structured database\n",
    "# In a real system, this would be a SQL database, but we'll use an in-memory dict\n",
    "structured_database = {\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"id\": \"P001\",\n",
    "            \"name\": \"CloudFlow API Gateway\",\n",
    "            \"category\": \"API Management\",\n",
    "            \"price\": 299.99,\n",
    "            \"release_date\": \"2024-01-15\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"P002\",\n",
    "            \"name\": \"DockerPro Container Suite\",\n",
    "            \"category\": \"DevOps\",\n",
    "            \"price\": 499.99,\n",
    "            \"release_date\": \"2023-11-20\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"P003\",\n",
    "            \"name\": \"TransformerAI Model Kit\",\n",
    "            \"category\": \"Machine Learning\",\n",
    "            \"price\": 1299.99,\n",
    "            \"release_date\": \"2024-03-10\"\n",
    "        }\n",
    "    ],\n",
    "    \"sales_q1_2024\": [\n",
    "        {\"product_id\": \"P001\", \"units_sold\": 1520, \"revenue\": 455848.00},\n",
    "        {\"product_id\": \"P002\", \"units_sold\": 890, \"revenue\": 444991.00},\n",
    "        {\"product_id\": \"P003\", \"units_sold\": 340, \"revenue\": 441996.60}\n",
    "    ],\n",
    "    \"sales_q2_2024\": [\n",
    "        {\"product_id\": \"P001\", \"units_sold\": 1680, \"revenue\": 503832.00},\n",
    "        {\"product_id\": \"P002\", \"units_sold\": 1050, \"revenue\": 524989.50},\n",
    "        {\"product_id\": \"P003\", \"units_sold\": 420, \"revenue\": 545995.80}\n",
    "    ]\n",
    "}\n",
    "\n",
    "def query_structured_data(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Queries the structured database based on natural language input.\n",
    "    This simulates a SQL query interface.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language query about products or sales\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with relevant structured data\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Simple keyword-based routing (in real systems, use NL-to-SQL)\n",
    "    if any(word in query_lower for word in ['product', 'price', 'category', 'release']):\n",
    "        results['products'] = structured_database['products']\n",
    "    \n",
    "    if any(word in query_lower for word in ['sales', 'revenue', 'sold', 'q1', 'q2', 'quarter']):\n",
    "        if 'q1' in query_lower or 'first quarter' in query_lower:\n",
    "            results['sales_q1_2024'] = structured_database['sales_q1_2024']\n",
    "        elif 'q2' in query_lower or 'second quarter' in query_lower:\n",
    "            results['sales_q2_2024'] = structured_database['sales_q2_2024']\n",
    "        else:\n",
    "            # Return all sales data if no specific quarter mentioned\n",
    "            results['sales_q1_2024'] = structured_database['sales_q1_2024']\n",
    "            results['sales_q2_2024'] = structured_database['sales_q2_2024']\n",
    "    \n",
    "    # If no matches, return all data\n",
    "    if not results:\n",
    "        results = structured_database\n",
    "    \n",
    "    return json.dumps(results, indent=2)\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing structured data query:\")\n",
    "test_result = query_structured_data(\"What were the Q1 sales?\")\n",
    "print(test_result[:200] + \"...\")\n",
    "print(\"\\n✓ Structured database configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604312c",
   "metadata": {},
   "source": [
    "### Source 3: Web Search (Simulated)\n",
    "A simulated web search tool for \"current\" information not in our knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0404812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing web search:\n",
      "Web search results for 'What are the latest AI trends?':\n",
      "\n",
      "1. Top AI Trends in 2024 - TechCrunch (2024-10-10)\n",
      "   The AI landscape continues to evolve rapidly with multimodal models, improved reasoning capabilities, and more efficient training methods leading the charge.\n",
      "\n",
      "2. Enterprise AI Adoption Reaches New Heights (2024-10-08)\n",
      "   Recent surveys show 78% of enterprises are now deploying AI in production, with RAG-based systems being the most common architecture.\n",
      "\n",
      "\n",
      "✓ Web search tool configured\n"
     ]
    }
   ],
   "source": [
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates a web search API (like Bing or Google Search).\n",
    "    In production, this would call an actual search API.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "    \n",
    "    Returns:\n",
    "        Simulated search results as a formatted string\n",
    "    \"\"\"\n",
    "    # Simulated search results for demonstration\n",
    "    search_results = {\n",
    "        \"ai trends\": [\n",
    "            {\n",
    "                \"title\": \"Top AI Trends in 2024 - TechCrunch\",\n",
    "                \"snippet\": \"The AI landscape continues to evolve rapidly with multimodal models, improved reasoning capabilities, and more efficient training methods leading the charge.\",\n",
    "                \"date\": \"2024-10-10\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Enterprise AI Adoption Reaches New Heights\",\n",
    "                \"snippet\": \"Recent surveys show 78% of enterprises are now deploying AI in production, with RAG-based systems being the most common architecture.\",\n",
    "                \"date\": \"2024-10-08\"\n",
    "            }\n",
    "        ],\n",
    "        \"market sentiment\": [\n",
    "            {\n",
    "                \"title\": \"AI Market Sentiment Analysis - October 2024\",\n",
    "                \"snippet\": \"Market analysts report overwhelmingly positive sentiment towards AI infrastructure products, particularly those focused on enterprise deployment.\",\n",
    "                \"date\": \"2024-10-12\"\n",
    "            }\n",
    "        ],\n",
    "        \"gpt-5\": [\n",
    "            {\n",
    "                \"title\": \"OpenAI Announces GPT-5 Development\",\n",
    "                \"snippet\": \"OpenAI has confirmed that GPT-5 is in development, promising significant improvements in reasoning and reduced hallucination rates.\",\n",
    "                \"date\": \"2024-10-15\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Find matching results\n",
    "    relevant_results = []\n",
    "    for keyword, results in search_results.items():\n",
    "        if keyword in query_lower:\n",
    "            relevant_results.extend(results)\n",
    "    \n",
    "    # Default results if no match\n",
    "    if not relevant_results:\n",
    "        return f\"Web search for '{query}': No recent results found. This information may not be available via web search.\"\n",
    "    \n",
    "    # Format results\n",
    "    formatted = f\"Web search results for '{query}':\\n\\n\"\n",
    "    for i, result in enumerate(relevant_results, 1):\n",
    "        formatted += f\"{i}. {result['title']} ({result['date']})\\n\"\n",
    "        formatted += f\"   {result['snippet']}\\n\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing web search:\")\n",
    "test_result = web_search(\"What are the latest AI trends?\")\n",
    "print(test_result)\n",
    "print(\"✓ Web search tool configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b535a9f",
   "metadata": {},
   "source": [
    "## 4. Tool Definitions for the Agent\n",
    "\n",
    "Now we'll wrap each data source in a **Tool** that the agent can use. Each tool has:\n",
    "- A **name**: Identifier for the tool\n",
    "- A **description**: Critical! This tells the agent *when* to use this tool\n",
    "- A **function**: The actual callable that performs the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea22e041",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_query_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tool 1: Document Search (Vector Database)\u001b[39;00m\n\u001b[32m      2\u001b[39m document_search_tool = QueryEngineTool.from_defaults(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     query_engine=\u001b[43mvector_query_engine\u001b[49m,\n\u001b[32m      4\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mdocument_search\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     description=(\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse this tool to search technical documentation about software technologies, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAPIs, machine learning models, and software architectures. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis tool is best for questions about \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhow does X work?\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwhat is X?\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplain the architecture of X\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m     )\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Tool 2: Structured Data Query (Simulated SQL)\u001b[39;00m\n\u001b[32m     14\u001b[39m structured_data_tool = FunctionTool.from_defaults(\n\u001b[32m     15\u001b[39m     fn=query_structured_data,\n\u001b[32m     16\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mdatabase_query\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     )\n\u001b[32m     23\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'vector_query_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# Tool 1: Document Search (Vector Database)\n",
    "document_search_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    name=\"document_search\",\n",
    "    description=(\n",
    "        \"Use this tool to search technical documentation about software technologies, \"\n",
    "        \"APIs, machine learning models, and software architectures. \"\n",
    "        \"This tool is best for questions about 'how does X work?', 'what is X?', \"\n",
    "        \"or 'explain the architecture of X'.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tool 2: Structured Data Query (Simulated SQL)\n",
    "structured_data_tool = FunctionTool.from_defaults(\n",
    "    fn=query_structured_data,\n",
    "    name=\"database_query\",\n",
    "    description=(\n",
    "        \"Use this tool to query structured business data including product information \"\n",
    "        \"(names, prices, categories, release dates) and sales data (revenue, units sold). \"\n",
    "        \"This tool is best for questions about 'what products do we have?', \"\n",
    "        \"'what were the Q1/Q2 sales?', or 'how much revenue did product X generate?'.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tool 3: Web Search (Simulated)\n",
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=web_search,\n",
    "    name=\"web_search\",\n",
    "    description=(\n",
    "        \"Use this tool to search for current information, recent news, market trends, \"\n",
    "        \"or information that is not in the internal documentation or database. \"\n",
    "        \"This tool is best for questions about 'latest trends', 'current market sentiment', \"\n",
    "        \"'recent developments', or 'what's new in X?'.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Collect all tools\n",
    "agent_tools = [document_search_tool, structured_data_tool, web_search_tool]\n",
    "\n",
    "print(\"✓ Created 3 tools for the agent:\")\n",
    "for tool in agent_tools:\n",
    "    print(f\"  - {tool.metadata.name}: {tool.metadata.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b92c6",
   "metadata": {},
   "source": [
    "## 5. Create the ReAct Agent\n",
    "\n",
    "The **ReActAgent** implements the Reason-Act-Observe loop. It will:\n",
    "1. Reason about which tool(s) to use\n",
    "2. Act by calling the selected tool(s)\n",
    "3. Observe the results\n",
    "4. Repeat if needed or synthesize a final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ReAct agent\n",
    "agent = ReActAgent.from_tools(\n",
    "    agent_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,  # Show reasoning traces\n",
    "    max_iterations=10  # Maximum reasoning steps to prevent infinite loops\n",
    ")\n",
    "\n",
    "print(\"✓ ReAct Agent created\")\n",
    "print(f\"  Available tools: {len(agent_tools)}\")\n",
    "print(f\"  Max iterations: 10\")\n",
    "print(f\"  Verbose mode: Enabled (will show reasoning traces)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed36fd",
   "metadata": {},
   "source": [
    "## 6. Test Scenarios: Single-Source Queries\n",
    "\n",
    "Let's start with queries that require only one data source. We'll observe how the agent **autonomously decides** which tool to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb5ec1",
   "metadata": {},
   "source": [
    "### Scenario 1: Document Search Query\n",
    "Query about technical concepts (should use `document_search`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCENARIO 1: Technical Documentation Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_1 = \"What is the transformer architecture and how does it work?\"\n",
    "print(f\"\\nQuery: {query_1}\\n\")\n",
    "\n",
    "response_1 = agent.chat(query_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c6c62",
   "metadata": {},
   "source": [
    "**Observe the agent's reasoning trace above:**\n",
    "- The agent should recognize this is a technical question\n",
    "- It should select the `document_search` tool\n",
    "- It should provide an answer based on the retrieved documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60e178",
   "metadata": {},
   "source": [
    "### Scenario 2: Structured Data Query\n",
    "Query about business data (should use `database_query`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db933370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCENARIO 2: Structured Database Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_2 = \"What were the Q2 2024 sales figures for all products?\"\n",
    "print(f\"\\nQuery: {query_2}\\n\")\n",
    "\n",
    "response_2 = agent.chat(query_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa51e5",
   "metadata": {},
   "source": [
    "**Observe the agent's reasoning:**\n",
    "- The agent should recognize this requires structured sales data\n",
    "- It should select the `database_query` tool\n",
    "- It should provide formatted sales figures from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00a7d4",
   "metadata": {},
   "source": [
    "### Scenario 3: Web Search Query\n",
    "Query about current events (should use `web_search`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3210b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCENARIO 3: Current Information / Web Search Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_3 = \"What are the latest trends in AI for 2024?\"\n",
    "print(f\"\\nQuery: {query_3}\\n\")\n",
    "\n",
    "response_3 = agent.chat(query_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b43c65",
   "metadata": {},
   "source": [
    "**Observe the agent's reasoning:**\n",
    "- The agent should recognize this requires current/recent information\n",
    "- It should select the `web_search` tool\n",
    "- It should synthesize the simulated web search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f5317",
   "metadata": {},
   "source": [
    "## 7. Advanced Scenario: Multi-Source Query\n",
    "\n",
    "Now the real power: a query that **requires information from multiple sources**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95937f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCENARIO 4: Multi-Source Query (The Agentic RAG Advantage)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_4 = (\n",
    "    \"Compare our TransformerAI Model Kit product with current AI market trends. \"\n",
    "    \"Include pricing information and recent sales performance.\"\n",
    ")\n",
    "print(f\"\\nQuery: {query_4}\\n\")\n",
    "print(\"This query requires:\")\n",
    "print(\"  1. Product information (database_query)\")\n",
    "print(\"  2. Technical details about transformers (document_search)\")\n",
    "print(\"  3. Market trends (web_search)\")\n",
    "print(\"\\nLet's see how the agent handles this...\\n\")\n",
    "\n",
    "response_4 = agent.chat(query_4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcab88b",
   "metadata": {},
   "source": [
    "**Observe the multi-step reasoning:**\n",
    "- The agent should identify that this query requires multiple pieces of information\n",
    "- It should make multiple tool calls:\n",
    "  - `database_query` for product pricing and sales data\n",
    "  - `web_search` for market trends\n",
    "  - Possibly `document_search` for technical context on transformers\n",
    "- It should **synthesize** all this information into a coherent response\n",
    "\n",
    "This is the quintessential **Agentic RAG** capability: autonomous orchestration of multiple data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab522f",
   "metadata": {},
   "source": [
    "## 8. Comparative Analysis: Agentic vs. Standard RAG\n",
    "\n",
    "Let's demonstrate what happens when we try to answer the multi-source query with a **standard, single-source RAG system**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: Standard RAG (Document-Only) vs. Agentic RAG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n--- STANDARD RAG (Vector Search Only) ---\\n\")\n",
    "standard_rag_response = vector_query_engine.query(query_4)\n",
    "print(f\"Query: {query_4}\\n\")\n",
    "print(f\"Response: {standard_rag_response}\\n\")\n",
    "\n",
    "print(\"\\n--- AGENTIC RAG (Multi-Source) ---\\n\")\n",
    "print(f\"Query: {query_4}\\n\")\n",
    "print(f\"Response: {response_4}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589cbdc",
   "metadata": {},
   "source": [
    "## 9. Analysis and Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "analysis = \"\"\"\n",
    "## Comparative Analysis\n",
    "\n",
    "### Standard RAG Limitations\n",
    "\n",
    "The standard vector-only RAG system:\n",
    "- ✗ **Cannot access structured data** (pricing, sales figures)\n",
    "- ✗ **Cannot access current information** (market trends from web)\n",
    "- ✗ **Limited to one data source** (technical documentation only)\n",
    "- ✗ **Inflexible**: Always uses the same retrieval strategy regardless of query type\n",
    "\n",
    "For the multi-source query, it likely:\n",
    "- Provided technical information about transformers (what it *can* retrieve)\n",
    "- Could not provide pricing or sales data (not in documents)\n",
    "- Could not provide market trends (not in its knowledge base)\n",
    "- **Incomplete answer** due to architectural limitations\n",
    "\n",
    "### Agentic RAG Advantages\n",
    "\n",
    "The agentic system:\n",
    "- ✓ **Multi-source capability**: Can query vector DB, structured DB, and web search\n",
    "- ✓ **Autonomous routing**: Intelligently selects the right tool(s) for each query\n",
    "- ✓ **Dynamic workflow**: Can adjust strategy based on intermediate results\n",
    "- ✓ **Information synthesis**: Combines data from multiple sources into coherent answers\n",
    "- ✓ **Transparent reasoning**: Shows its decision-making process (Reason-Act-Observe traces)\n",
    "- ✓ **Self-correcting**: Can try different approaches if initial attempts fail\n",
    "\n",
    "For the multi-source query, it:\n",
    "- Identified the need for product data → called `database_query`\n",
    "- Identified the need for market trends → called `web_search`\n",
    "- Possibly identified need for technical context → called `document_search`\n",
    "- **Synthesized all sources** into a comprehensive, complete answer\n",
    "\n",
    "## The Paradigm Shift\n",
    "\n",
    "| Aspect | Traditional RAG | Agentic RAG |\n",
    "|--------|----------------|-------------|\n",
    "| **Workflow** | Static: retrieve → generate | Dynamic: reason → act → observe → repeat |\n",
    "| **Data Sources** | Single source (typically vector DB) | Multiple heterogeneous sources |\n",
    "| **Decision Making** | Fixed pipeline | LLM-orchestrated, adaptive |\n",
    "| **LLM Role** | Generator only | Generator + Orchestrator + Meta-reasoner |\n",
    "| **Complexity** | Simple, linear | Complex, iterative |\n",
    "| **Best For** | Straightforward Q&A over documents | Multi-source synthesis, complex reasoning tasks |\n",
    "| **Enterprise Viability** | Limited to document search use cases | Viable for complex, real-world scenarios |\n",
    "\n",
    "## When to Use Agentic RAG\n",
    "\n",
    "**Choose Agentic RAG when:**\n",
    "1. Queries require information from **multiple data sources** (documents, databases, APIs)\n",
    "2. You need **dynamic routing** based on query characteristics\n",
    "3. Tasks involve **multi-step reasoning** where intermediate results inform next steps\n",
    "4. You need **transparency** in the system's decision-making process\n",
    "5. The domain requires **synthesis** of structured + unstructured + external data\n",
    "\n",
    "**Stick with traditional RAG when:**\n",
    "1. All information is in a **single, homogeneous source**\n",
    "2. Queries are **straightforward** and don't require multi-step reasoning\n",
    "3. **Latency** and **cost** are critical (agents make multiple LLM calls)\n",
    "4. The use case is **document search only**\n",
    "\n",
    "## The LLM as Meta-Reasoner\n",
    "\n",
    "The key insight of Agentic RAG is that the LLM performs **meta-reasoning**:\n",
    "- \"What information do I need?\"\n",
    "- \"Where can I find it?\"\n",
    "- \"Is what I found sufficient?\"\n",
    "- \"Do I need to search again with a different strategy?\"\n",
    "\n",
    "This elevates the LLM from a **text generator** to the **central intelligence** of a complex system—the \"brain\" that coordinates multiple specialized tools to solve problems that are intractable for simpler architectures.\n",
    "\n",
    "## Production Considerations\n",
    "\n",
    "When deploying Agentic RAG in production:\n",
    "\n",
    "1. **Cost Management**: Agents make multiple LLM calls. Monitor token usage carefully.\n",
    "2. **Latency**: Multi-step reasoning takes time. Consider async execution and user experience.\n",
    "3. **Reliability**: Implement max iteration limits and fallback strategies to prevent infinite loops.\n",
    "4. **Tool Descriptions**: The quality of tool descriptions is critical—they guide the agent's routing decisions.\n",
    "5. **Observability**: Log all reasoning traces for debugging and system improvement.\n",
    "6. **Security**: Validate tool calls and implement access controls for sensitive data sources.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be481d21",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "In this demo, we successfully built and tested an **Agentic RAG system** with:\n",
    "\n",
    "1. **Three heterogeneous data sources**:\n",
    "   - Vector database for technical documentation\n",
    "   - Structured database for product/sales data\n",
    "   - Web search for current information\n",
    "\n",
    "2. **ReAct agent architecture** with:\n",
    "   - Autonomous tool selection and routing\n",
    "   - Transparent Reason-Act-Observe reasoning traces\n",
    "   - Multi-source information synthesis\n",
    "\n",
    "3. **Comprehensive testing** showing:\n",
    "   - Correct single-source routing for simple queries\n",
    "   - Multi-source orchestration for complex queries\n",
    "   - Clear advantages over standard, single-source RAG\n",
    "\n",
    "### Architectural Significance\n",
    "\n",
    "Agentic RAG represents a fundamental evolution:\n",
    "- **From static pipelines to dynamic orchestration**\n",
    "- **From single-source to multi-source synthesis**\n",
    "- **From passive generators to active meta-reasoners**\n",
    "\n",
    "This architecture makes RAG viable for **real-world enterprise scenarios** where knowledge is fragmented across multiple systems and queries require intelligent routing and multi-step reasoning.\n",
    "\n",
    "### Integration with Previous Concepts\n",
    "\n",
    "Agentic RAG builds on and extends the techniques from previous demos:\n",
    "- **Query enhancement** (HyDE, multi-query) can be tools the agent selects\n",
    "- **Hybrid search** can be one of multiple retrieval strategies\n",
    "- **Re-ranking** can be applied to results from any tool\n",
    "- **Corrective RAG** and **Self-RAG** are natural fits for agent-based self-correction\n",
    "\n",
    "The agent becomes the **orchestration layer** that intelligently applies these techniques based on the specific characteristics of each query.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To extend this demo:\n",
    "1. **Add more tools**: Image search, code execution, real-time data feeds\n",
    "2. **Implement plan-and-execute**: Pre-plan multi-step queries for efficiency\n",
    "3. **Add memory**: Allow the agent to remember conversation context\n",
    "4. **Integrate GraphRAG**: Add graph traversal as another tool\n",
    "5. **Production hardening**: Add error handling, retry logic, and observability\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- Curriculum: \"The Autonomous Frontier: Agentic RAG Architectures\"\n",
    "- *What is Agentic RAG?* | IBM (Reference 57)\n",
    "- *GraphRAG and Agentic Architecture* - Neo4j (Reference 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
