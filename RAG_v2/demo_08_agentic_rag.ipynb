{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc2a898",
   "metadata": {},
   "source": [
    "# Demo #8: Agentic RAG - Autonomous Query Planning and Tool Selection\n",
    "\n",
    "## Objective\n",
    "Demonstrate an autonomous agent that dynamically plans retrieval strategies and selects appropriate tools to answer complex queries. This demo extends beyond internal knowledge bases to include **internet search** and **arXiv academic paper access**.\n",
    "\n",
    "## Core Concepts\n",
    "- **Agentic workflow**: Thought ‚Üí Action ‚Üí Observation loop (ReAct framework)\n",
    "- **Dynamic tool selection**: Agent chooses which knowledge base or external source to query\n",
    "- **Multi-step reasoning**: Agent decomposes complex questions into sub-tasks\n",
    "- **Query decomposition and planning**: Autonomous strategy formulation\n",
    "- **External tool integration**: Internet search, arXiv research papers, and more\n",
    "\n",
    "## What is Agentic RAG?\n",
    "\n",
    "Traditional RAG is **passive**: it retrieves from a single, fixed knowledge base and generates an answer.\n",
    "\n",
    "**Agentic RAG** is **active**: it uses an LLM-powered agent that:\n",
    "1. **Analyzes** the query to understand requirements\n",
    "2. **Plans** which knowledge sources to consult (internal + external)\n",
    "3. **Executes** multi-step retrieval strategies\n",
    "4. **Adapts** based on retrieved information\n",
    "5. **Synthesizes** information from multiple sources\n",
    "\n",
    "### Static RAG vs. Agentic RAG\n",
    "\n",
    "**Static RAG:**\n",
    "```\n",
    "Query ‚Üí Single Vector DB ‚Üí Retrieve Top-K ‚Üí Generate\n",
    "```\n",
    "- ‚ùå No query analysis\n",
    "- ‚ùå Fixed retrieval strategy\n",
    "- ‚ùå Single knowledge source\n",
    "- ‚ùå No multi-hop reasoning\n",
    "- ‚ùå Limited to internal knowledge base\n",
    "- ‚ùå Cannot access current information\n",
    "\n",
    "**Agentic RAG:**\n",
    "```\n",
    "Query ‚Üí Agent Analyzes\n",
    "          ‚Üì\n",
    "    Plans retrieval strategy\n",
    "          ‚Üì\n",
    "    Selects Tool(s): Internal KB | Internet | arXiv | APIs\n",
    "          ‚Üì\n",
    "    Tool 1 ‚Üí Retrieve ‚Üí Observation\n",
    "          ‚Üì\n",
    "    Needs more info?\n",
    "          ‚Üì\n",
    "    Tool 2 ‚Üí Retrieve ‚Üí Observation\n",
    "          ‚Üì\n",
    "    Synthesize all observations ‚Üí Generate\n",
    "```\n",
    "- ‚úÖ Intelligent query understanding\n",
    "- ‚úÖ Dynamic strategy selection\n",
    "- ‚úÖ Multiple knowledge sources (internal + external)\n",
    "- ‚úÖ Multi-hop reasoning\n",
    "- ‚úÖ Access to current information via internet\n",
    "- ‚úÖ Integration with academic research (arXiv)\n",
    "- ‚úÖ Extensible to any API or tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c2d49",
   "metadata": {},
   "source": [
    "## ReAct Framework\n",
    "\n",
    "The agent uses the **ReAct** (Reasoning + Acting) pattern:\n",
    "\n",
    "```\n",
    "Loop:\n",
    "  1. Thought: \"I need information about X\"\n",
    "  2. Action: Use tool Y with query Z\n",
    "  3. Observation: Retrieved information\n",
    "  4. Thought: \"This partially answers the question, but I need more about A\"\n",
    "  5. Action: Use tool W with query B\n",
    "  6. Observation: Additional information\n",
    "  7. Thought: \"Now I have enough information\"\n",
    "  8. Final Answer: Synthesized response\n",
    "```\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "1. **Cross-domain queries**: \"How can ML improve financial portfolio management?\"\n",
    "   - Queries ML knowledge base\n",
    "   - Queries finance knowledge base\n",
    "   - Synthesizes both\n",
    "\n",
    "2. **Multi-hop reasoning**: \"Compare X vs. Y considering factors A, B, and C\"\n",
    "   - Retrieves info about X\n",
    "   - Retrieves info about Y\n",
    "   - Retrieves info about factors A, B, C\n",
    "   - Performs comparative analysis\n",
    "\n",
    "3. **Current information**: \"What are the latest developments in GPT-4?\"\n",
    "   - Uses internet search for current information\n",
    "   - Accesses recent news and updates\n",
    "   - Synthesizes current state\n",
    "\n",
    "4. **Academic research**: \"Find recent papers on Retrieval-Augmented Generation\"\n",
    "   - Searches arXiv for relevant papers\n",
    "   - Fetches specific papers for details\n",
    "   - Summarizes research findings\n",
    "\n",
    "5. **Hybrid queries**: \"Explain RL theory and find recent research applications\"\n",
    "   - Internal knowledge for fundamentals\n",
    "   - arXiv for latest research\n",
    "   - Comprehensive synthesis\n",
    "\n",
    "## Available Tools in This Demo\n",
    "\n",
    "1. **machine_learning_knowledge**: Internal ML concepts database\n",
    "2. **finance_knowledge**: Internal finance and trading database\n",
    "3. **internet_search**: DuckDuckGo search for current information\n",
    "4. **arxiv_search**: Search academic papers on arXiv.org\n",
    "5. **arxiv_fetch_paper**: Fetch specific papers by arXiv ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2c0d9",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies and Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell if packages are not already installed\n",
    "# !pip install llama-index llama-index-llms-azure-openai llama-index-embeddings-azure-openai\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify Azure OpenAI credentials\n",
    "required_vars = [\n",
    "    'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_ENDPOINT',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'AZURE_OPENAI_DEPLOYMENT_NAME',\n",
    "    'AZURE_OPENAI_EMBEDDING_DEPLOYMENT'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"\\nPlease create a .env file with:\")\n",
    "    for var in missing_vars:\n",
    "        print(f\"{var}=<your_value>\")\n",
    "else:\n",
    "    print(\"‚úÖ All required environment variables are set\")\n",
    "    print(f\"   Endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "    print(f\"   Deployment: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}\")\n",
    "    print(f\"   Embedding: {os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68fddd",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Azure OpenAI Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff514f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Initialize Azure OpenAI LLM\n",
    "azure_llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    temperature=0.0  # Deterministic for consistent comparisons\n",
    ")\n",
    "\n",
    "# Initialize Azure OpenAI Embedding Model\n",
    "azure_embed = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    ")\n",
    "\n",
    "# Set global defaults\n",
    "Settings.llm = azure_llm\n",
    "Settings.embed_model = azure_embed\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI components initialized\")\n",
    "print(f\"   LLM: {azure_llm.model}\")\n",
    "print(f\"   Embeddings: {azure_embed.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3ac24",
   "metadata": {},
   "source": [
    "## Step 2: Load and Index Machine Learning Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Define paths\n",
    "ml_data_path = \"./data/ml_concepts\"\n",
    "\n",
    "print(\"üìÅ Loading Machine Learning documents...\")\n",
    "\n",
    "# Load ML documents\n",
    "ml_documents = SimpleDirectoryReader(\n",
    "    input_dir=ml_data_path,\n",
    "    recursive=False,\n",
    "    required_exts=[\".md\"]\n",
    ").load_data()\n",
    "\n",
    "print(f\"   Loaded {len(ml_documents)} ML documents\")\n",
    "for doc in ml_documents:\n",
    "    print(f\"   - {doc.metadata.get('file_name', 'Unknown')}\")\n",
    "\n",
    "# Parse into chunks\n",
    "parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "ml_nodes = parser.get_nodes_from_documents(ml_documents)\n",
    "print(f\"\\n   Parsed into {len(ml_nodes)} chunks\")\n",
    "\n",
    "# Create vector index\n",
    "print(\"\\nüîç Creating ML vector index...\")\n",
    "ml_index = VectorStoreIndex(ml_nodes, embed_model=azure_embed)\n",
    "print(\"‚úÖ ML index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42338c",
   "metadata": {},
   "source": [
    "## Step 3: Load and Index Finance Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fccbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "finance_data_path = \"./data/finance_docs\"\n",
    "\n",
    "print(\"üìÅ Loading Finance documents...\")\n",
    "\n",
    "# Load Finance documents\n",
    "finance_documents = SimpleDirectoryReader(\n",
    "    input_dir=finance_data_path,\n",
    "    recursive=False,\n",
    "    required_exts=[\".md\"]\n",
    ").load_data()\n",
    "\n",
    "print(f\"   Loaded {len(finance_documents)} Finance documents\")\n",
    "for doc in finance_documents:\n",
    "    print(f\"   - {doc.metadata.get('file_name', 'Unknown')}\")\n",
    "\n",
    "# Parse into chunks\n",
    "finance_nodes = parser.get_nodes_from_documents(finance_documents)\n",
    "print(f\"\\n   Parsed into {len(finance_nodes)} chunks\")\n",
    "\n",
    "# Create vector index\n",
    "print(\"\\nüîç Creating Finance vector index...\")\n",
    "finance_index = VectorStoreIndex(finance_nodes, embed_model=azure_embed)\n",
    "print(\"‚úÖ Finance index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75ea28",
   "metadata": {},
   "source": [
    "## Step 4: Create Query Engine Tools for Agent\n",
    "\n",
    "We wrap each knowledge base in a tool that the agent can use. Each tool has:\n",
    "- **name**: Identifier for the tool\n",
    "- **description**: Helps the agent decide when to use this tool\n",
    "- **query_engine**: The actual retrieval system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbedb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# Create query engines\n",
    "ml_query_engine = ml_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "finance_query_engine = finance_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "# Wrap in tools with descriptive metadata\n",
    "ml_tool = QueryEngineTool(\n",
    "    query_engine=ml_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"machine_learning_knowledge\",\n",
    "        description=(\n",
    "            \"Provides expert knowledge about machine learning algorithms, concepts, and techniques. \"\n",
    "            \"Use this tool for questions about: neural networks, gradient boosting, random forests, \"\n",
    "            \"support vector machines, k-means clustering, deep learning, reinforcement learning, \"\n",
    "            \"model training, optimization, and ML theory.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "finance_tool = QueryEngineTool(\n",
    "    query_engine=finance_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"finance_knowledge\",\n",
    "        description=(\n",
    "            \"Provides information about financial concepts, investment strategies, and market analysis. \"\n",
    "            \"Use this tool for questions about: portfolio management, diversification, risk management, \"\n",
    "            \"quantitative trading, technical analysis, market indicators, investment strategies, \"\n",
    "            \"and financial markets.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Query engine tools created:\")\n",
    "print(f\"   1. {ml_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {ml_tool.metadata.description[:80]}...\")\n",
    "print(f\"\\n   2. {finance_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {finance_tool.metadata.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82307454",
   "metadata": {},
   "source": [
    "## Step 4.5: Create Internet Search and arXiv Tools\n",
    "\n",
    "In addition to our internal knowledge bases, we'll add tools that can access external information:\n",
    "- **Internet Search**: For current information and topics outside our knowledge bases\n",
    "- **arXiv Search**: For recent research papers and academic publications\n",
    "- **arXiv Fetch**: To retrieve and read specific arXiv papers\n",
    "\n",
    "These tools demonstrate the extensibility of the agentic framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional required packages for web search and arXiv\n",
    "# !pip install duckduckgo-search arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04414a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "# Import web search libraries\n",
    "try:\n",
    "    from duckduckgo_search import DDGS\n",
    "    import arxiv\n",
    "    print(\"‚úÖ Web search and arXiv libraries loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Import error: {e}\")\n",
    "    print(\"   Please install: pip install duckduckgo-search arxiv\")\n",
    "\n",
    "# Define internet search function\n",
    "def internet_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Search the internet for current information using DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        max_results: Maximum number of results to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(query, max_results=max_results))\n",
    "        \n",
    "        if not results:\n",
    "            return f\"No results found for query: {query}\"\n",
    "        \n",
    "        formatted_results = f\"Internet search results for '{query}':\\n\\n\"\n",
    "        for i, result in enumerate(results, 1):\n",
    "            title = result.get('title', 'No title')\n",
    "            snippet = result.get('body', 'No description')\n",
    "            url = result.get('href', 'No URL')\n",
    "            formatted_results += f\"{i}. **{title}**\\n\"\n",
    "            formatted_results += f\"   {snippet}\\n\"\n",
    "            formatted_results += f\"   Source: {url}\\n\\n\"\n",
    "        \n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        return f\"Error performing internet search: {str(e)}\"\n",
    "\n",
    "# Define arXiv search function\n",
    "def arxiv_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Search arXiv for research papers.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        max_results: Maximum number of papers to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with paper information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        \n",
    "        papers = list(search.results())\n",
    "        \n",
    "        if not papers:\n",
    "            return f\"No arXiv papers found for query: {query}\"\n",
    "        \n",
    "        formatted_results = f\"arXiv search results for '{query}':\\n\\n\"\n",
    "        for i, paper in enumerate(papers, 1):\n",
    "            formatted_results += f\"{i}. **{paper.title}**\\n\"\n",
    "            formatted_results += f\"   Authors: {', '.join([author.name for author in paper.authors])}\\n\"\n",
    "            formatted_results += f\"   Published: {paper.published.strftime('%Y-%m-%d')}\\n\"\n",
    "            formatted_results += f\"   arXiv ID: {paper.entry_id.split('/')[-1]}\\n\"\n",
    "            formatted_results += f\"   Summary: {paper.summary[:300]}...\\n\"\n",
    "            formatted_results += f\"   URL: {paper.entry_id}\\n\\n\"\n",
    "        \n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        return f\"Error searching arXiv: {str(e)}\"\n",
    "\n",
    "# Define arXiv fetch function\n",
    "def arxiv_fetch_paper(arxiv_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch and read a specific arXiv paper by its ID.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: The arXiv paper ID (e.g., '2301.12345' or 'cs.AI/2301.12345')\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with detailed paper information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the arxiv_id\n",
    "        arxiv_id = arxiv_id.replace('arxiv:', '').replace('arXiv:', '')\n",
    "        arxiv_id = arxiv_id.split('/')[-1]  # Handle URLs\n",
    "        \n",
    "        search = arxiv.Search(id_list=[arxiv_id])\n",
    "        paper = next(search.results(), None)\n",
    "        \n",
    "        if not paper:\n",
    "            return f\"No paper found with arXiv ID: {arxiv_id}\"\n",
    "        \n",
    "        result = f\"**arXiv Paper Details**\\n\\n\"\n",
    "        result += f\"**Title:** {paper.title}\\n\\n\"\n",
    "        result += f\"**Authors:** {', '.join([author.name for author in paper.authors])}\\n\\n\"\n",
    "        result += f\"**Published:** {paper.published.strftime('%Y-%m-%d')}\\n\\n\"\n",
    "        result += f\"**Updated:** {paper.updated.strftime('%Y-%m-%d')}\\n\\n\"\n",
    "        result += f\"**arXiv ID:** {paper.entry_id.split('/')[-1]}\\n\\n\"\n",
    "        result += f\"**Categories:** {', '.join(paper.categories)}\\n\\n\"\n",
    "        result += f\"**Abstract:**\\n{paper.summary}\\n\\n\"\n",
    "        result += f\"**PDF URL:** {paper.pdf_url}\\n\\n\"\n",
    "        result += f\"**Primary Category:** {paper.primary_category}\\n\"\n",
    "        \n",
    "        if paper.comment:\n",
    "            result += f\"\\n**Comments:** {paper.comment}\\n\"\n",
    "        \n",
    "        if paper.journal_ref:\n",
    "            result += f\"\\n**Journal Reference:** {paper.journal_ref}\\n\"\n",
    "        \n",
    "        if paper.doi:\n",
    "            result += f\"\\n**DOI:** {paper.doi}\\n\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching arXiv paper: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Search functions defined:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cac04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FunctionTool wrappers for the search functions\n",
    "\n",
    "internet_search_tool = FunctionTool.from_defaults(\n",
    "    fn=internet_search,\n",
    "    name=\"internet_search\",\n",
    "    description=(\n",
    "        \"Search the internet for current information, news, and topics not covered in the knowledge bases. \"\n",
    "        \"Use this tool when you need up-to-date information, current events, recent developments, \"\n",
    "        \"or information about topics outside the ML and Finance domains. \"\n",
    "        \"Particularly useful for: latest news, current market conditions, recent events, \"\n",
    "        \"general knowledge queries, and fact-checking.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "arxiv_search_tool = FunctionTool.from_defaults(\n",
    "    fn=arxiv_search,\n",
    "    name=\"arxiv_search\",\n",
    "    description=(\n",
    "        \"Search arXiv.org for academic research papers in various fields including machine learning, \"\n",
    "        \"AI, physics, mathematics, finance, and more. Use this tool when you need recent research papers, \"\n",
    "        \"academic publications, or scholarly articles. Returns paper titles, authors, abstracts, and arXiv IDs. \"\n",
    "        \"Useful for: latest research, academic insights, state-of-the-art methods, research trends.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "arxiv_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=arxiv_fetch_paper,\n",
    "    name=\"arxiv_fetch_paper\",\n",
    "    description=(\n",
    "        \"Fetch and read a specific arXiv paper by its ID. Use this tool when you have an arXiv ID \"\n",
    "        \"and want to get detailed information about that specific paper including full abstract, \"\n",
    "        \"authors, categories, and publication details. Provide the arXiv ID (e.g., '2301.12345').\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ External tools created:\")\n",
    "print(f\"   3. {internet_search_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {internet_search_tool.metadata.description[:80]}...\")\n",
    "print(f\"\\n   4. {arxiv_search_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {arxiv_search_tool.metadata.description[:80]}...\")\n",
    "print(f\"\\n   5. {arxiv_fetch_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {arxiv_fetch_tool.metadata.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eff0e5",
   "metadata": {},
   "source": [
    "## Step 5: Create ReAct Agent\n",
    "\n",
    "The **ReActAgent** implements the Reasoning + Acting pattern:\n",
    "- **Reasoning**: Agent thinks about what information it needs\n",
    "- **Acting**: Agent uses tools to gather information\n",
    "- **Loop**: Continues until it has enough information to answer\n",
    "\n",
    "We enable `verbose=True` to see the agent's internal reasoning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90110aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "# Create ReAct agent with all tools\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool, internet_search_tool, arxiv_search_tool, arxiv_fetch_tool],\n",
    "    llm=azure_llm,\n",
    "    verbose=True,  # Show reasoning process\n",
    "    max_iterations=10  # Increased for more complex queries with external tools\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ReAct Agent initialized with extended capabilities\")\n",
    "print(f\"   Available tools: {len(agent.get_tools())}\")\n",
    "print(f\"   Internal Knowledge: {ml_tool.metadata.name}, {finance_tool.metadata.name}\")\n",
    "print(f\"   External Tools: {internet_search_tool.metadata.name}, {arxiv_search_tool.metadata.name}, {arxiv_fetch_tool.metadata.name}\")\n",
    "print(f\"   Max iterations: 10\")\n",
    "print(f\"   Verbose: True (will show reasoning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd99ad3",
   "metadata": {},
   "source": [
    "## Step 6: Create Static RAG Baseline for Comparison\n",
    "\n",
    "To demonstrate the advantages of Agentic RAG, we'll create a static RAG system that simply combines both knowledge bases into one index. This represents the traditional approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Creating static RAG baseline (combined index)...\")\n",
    "\n",
    "# Combine all nodes\n",
    "combined_nodes = ml_nodes + finance_nodes\n",
    "print(f\"   Combined {len(combined_nodes)} chunks from both domains\")\n",
    "\n",
    "# Create combined index\n",
    "combined_index = VectorStoreIndex(combined_nodes, embed_model=azure_embed)\n",
    "static_query_engine = combined_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Static RAG baseline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43727cc8",
   "metadata": {},
   "source": [
    "## Test Scenario 1: Simple Single-Domain Query\n",
    "\n",
    "**Query**: \"Explain gradient boosting.\"\n",
    "\n",
    "This is a straightforward ML question. The agent should:\n",
    "1. Identify that this is about machine learning\n",
    "2. Use the ML knowledge tool\n",
    "3. Retrieve relevant information\n",
    "4. Provide an answer\n",
    "\n",
    "Expected: Agent uses only the ML tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be680d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 1: Simple Single-Domain Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_1 = \"Explain gradient boosting.\"\n",
    "print(f\"\\nüìù Query: {query_1}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with tool selection):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent (verbose=True will show reasoning)\n",
    "agent_response_1 = agent.chat(query_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_1 = static_query_engine.query(query_1)\n",
    "print(static_response_1.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_1.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73c5e7",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 1\n",
    "\n",
    "**What to observe:**\n",
    "- Agent's reasoning process (Thought ‚Üí Action ‚Üí Observation)\n",
    "- Tool selection (should choose ML tool)\n",
    "- Both approaches should provide good answers for single-domain queries\n",
    "- Agent might be more targeted in tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c573d7",
   "metadata": {},
   "source": [
    "## Test Scenario 2: Cross-Domain Query\n",
    "\n",
    "**Query**: \"How can machine learning be applied to stock market prediction and portfolio management?\"\n",
    "\n",
    "This requires information from BOTH domains:\n",
    "- **ML**: How ML models work, what algorithms are suitable\n",
    "- **Finance**: Portfolio management concepts, market dynamics\n",
    "\n",
    "Expected behavior:\n",
    "- Agent should recognize the cross-domain nature\n",
    "- Use ML tool to get ML information\n",
    "- Use Finance tool to get financial context\n",
    "- Synthesize information from both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 2: Cross-Domain Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_2 = \"How can machine learning be applied to stock market prediction and portfolio management?\"\n",
    "print(f\"\\nüìù Query: {query_2}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with multi-tool usage):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use both tools\n",
    "agent_response_2 = agent.chat(query_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_2.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_2 = static_query_engine.query(query_2)\n",
    "print(static_response_2.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_2.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a649ccc",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 2\n",
    "\n",
    "**Key differences:**\n",
    "\n",
    "**Agentic RAG:**\n",
    "- ‚úÖ Explicitly queries both ML and Finance tools\n",
    "- ‚úÖ Systematic retrieval from each domain\n",
    "- ‚úÖ Guaranteed coverage of both aspects\n",
    "- ‚úÖ Clear reasoning trail showing multi-step process\n",
    "\n",
    "**Static RAG:**\n",
    "- ‚ö†Ô∏è Relies on vector similarity alone\n",
    "- ‚ö†Ô∏è May miss one domain if embedding similarity is skewed\n",
    "- ‚ö†Ô∏è Top-3 chunks might all come from one domain\n",
    "- ‚ö†Ô∏è No guarantee of balanced coverage\n",
    "\n",
    "The agent's ability to **plan** and **execute** multi-step retrieval ensures comprehensive answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fba8b9",
   "metadata": {},
   "source": [
    "## Test Scenario 3: Complex Multi-Hop Query\n",
    "\n",
    "**Query**: \"Compare the risk-adjusted returns of portfolio strategies using reinforcement learning versus traditional diversification. Consider both the Sharpe ratio and maximum drawdown.\"\n",
    "\n",
    "This is a complex query requiring:\n",
    "1. **Reinforcement learning** knowledge (ML domain)\n",
    "2. **Portfolio diversification** strategies (Finance domain)\n",
    "3. **Risk metrics** like Sharpe ratio and max drawdown (Finance domain)\n",
    "4. **Synthesis** of ML approaches to finance problems\n",
    "\n",
    "Expected: Agent should:\n",
    "- Break down into sub-questions\n",
    "- Query ML tool for RL concepts\n",
    "- Query Finance tool for diversification strategies\n",
    "- Query Finance tool again for risk metrics\n",
    "- Perform comparative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22341716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 3: Complex Multi-Hop Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_3 = (\n",
    "    \"Compare the risk-adjusted returns of portfolio strategies using reinforcement learning \"\n",
    "    \"versus traditional diversification. Consider both the Sharpe ratio and maximum drawdown.\"\n",
    ")\n",
    "print(f\"\\nüìù Query: {query_3}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with multi-step reasoning):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use multiple queries across tools\n",
    "agent_response_3 = agent.chat(query_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_3.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_3 = static_query_engine.query(query_3)\n",
    "print(static_response_3.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_3.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fe80f",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 3\n",
    "\n",
    "**Agent's advantages become clear:**\n",
    "\n",
    "1. **Decomposition**: Agent breaks complex query into manageable sub-questions\n",
    "2. **Strategic retrieval**: Queries specific tools for specific information\n",
    "3. **Iterative refinement**: Can make follow-up queries if initial information is insufficient\n",
    "4. **Synthesis**: Combines information from multiple sources coherently\n",
    "\n",
    "**Static RAG limitations:**\n",
    "- Must rely on single query embedding matching multiple concepts\n",
    "- Top-K retrieval might miss important aspects\n",
    "- No ability to \"realize\" information is missing and query again\n",
    "- Less systematic coverage of complex multi-part questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f288d",
   "metadata": {},
   "source": [
    "## Test Scenario 4: External Knowledge - Internet Search\n",
    "\n",
    "**Query**: \"What are the latest developments in GPT-4 and how do they compare to Claude 3?\"\n",
    "\n",
    "This query requires **current information** that is NOT in our internal knowledge bases:\n",
    "- Latest developments in GPT-4 (released after our knowledge cutoff)\n",
    "- Information about Claude 3 (outside our domain)\n",
    "- Comparison of current models\n",
    "\n",
    "Expected behavior:\n",
    "- Agent should recognize this requires external information\n",
    "- Use the internet_search tool to find current information\n",
    "- Synthesize findings into a comprehensive answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8104b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 4: External Knowledge - Internet Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_4 = \"What are the latest developments in GPT-4 and how do they compare to Claude 3?\"\n",
    "print(f\"\\nüìù Query: {query_4}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with internet search capability):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use internet search tool\n",
    "agent_response_4 = agent.chat(query_4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_4.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc435f02",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 4\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "1. **Knowledge Gap Recognition**: Agent recognizes that internal knowledge bases don't contain this information\n",
    "2. **Tool Selection**: Chooses internet_search tool for current information\n",
    "3. **External Integration**: Successfully queries external sources\n",
    "4. **Synthesis**: Combines information from web search into coherent answer\n",
    "\n",
    "**This demonstrates:**\n",
    "- ‚úÖ Agent can handle queries beyond internal knowledge\n",
    "- ‚úÖ Seamless integration of external information sources\n",
    "- ‚úÖ No need to maintain constantly updated internal databases\n",
    "- ‚úÖ Access to the entire internet's knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558e939",
   "metadata": {},
   "source": [
    "## Test Scenario 5: Academic Research - arXiv Search and Fetch\n",
    "\n",
    "**Query**: \"Find recent research papers on Retrieval-Augmented Generation and summarize the key findings.\"\n",
    "\n",
    "This requires:\n",
    "- Searching academic literature on arXiv\n",
    "- Finding recent RAG papers\n",
    "- Potentially fetching specific papers for details\n",
    "- Synthesizing research findings\n",
    "\n",
    "Expected behavior:\n",
    "- Agent uses arxiv_search tool to find relevant papers\n",
    "- May use arxiv_fetch_paper for detailed information\n",
    "- Synthesizes academic findings into accessible summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 5: Academic Research - arXiv Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_5 = \"Find recent research papers on Retrieval-Augmented Generation and summarize the key findings.\"\n",
    "print(f\"\\nüìù Query: {query_5}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with arXiv search capability):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use arXiv search tool\n",
    "agent_response_5 = agent.chat(query_5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_5.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876e65d",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 5\n",
    "\n",
    "**Academic Research Integration:**\n",
    "\n",
    "1. **Research Discovery**: Agent uses arXiv search to find relevant academic papers\n",
    "2. **Multi-Paper Analysis**: Can search and compare multiple research papers\n",
    "3. **Detailed Fetching**: Can use arxiv_fetch_paper for specific papers if needed\n",
    "4. **Academic Synthesis**: Summarizes research findings in accessible language\n",
    "\n",
    "**This demonstrates:**\n",
    "- ‚úÖ Access to cutting-edge research\n",
    "- ‚úÖ Stay current with latest academic developments\n",
    "- ‚úÖ Integration of peer-reviewed sources\n",
    "- ‚úÖ Bridge between academic research and practical applications\n",
    "\n",
    "**Use cases:**\n",
    "- Literature reviews\n",
    "- Staying current with research trends\n",
    "- Finding state-of-the-art methods\n",
    "- Academic research support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1001058",
   "metadata": {},
   "source": [
    "## Test Scenario 6: Hybrid Multi-Tool Query\n",
    "\n",
    "**Query**: \"How is reinforcement learning currently being applied in algorithmic trading? Include both theoretical foundations from our knowledge base and recent research developments from arXiv.\"\n",
    "\n",
    "This is a **complex hybrid query** requiring:\n",
    "1. **Internal ML knowledge**: RL fundamentals, algorithms\n",
    "2. **Internal Finance knowledge**: Algorithmic trading concepts\n",
    "3. **External Research**: Recent arXiv papers on RL in trading\n",
    "4. **Synthesis**: Combine theoretical foundations with cutting-edge research\n",
    "\n",
    "Expected behavior:\n",
    "- Agent uses ML tool for RL theory\n",
    "- Agent uses Finance tool for trading concepts\n",
    "- Agent uses arXiv search for recent research\n",
    "- Comprehensive synthesis of all sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d06c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 6: Hybrid Multi-Tool Query (Internal + External)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_6 = (\n",
    "    \"How is reinforcement learning currently being applied in algorithmic trading? \"\n",
    "    \"Include both theoretical foundations from our knowledge base and recent research \"\n",
    "    \"developments from arXiv.\"\n",
    ")\n",
    "print(f\"\\nüìù Query: {query_6}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (orchestrating multiple tools):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use ML, Finance, and arXiv tools\n",
    "agent_response_6 = agent.chat(query_6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_6.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196940e",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 6\n",
    "\n",
    "**Ultimate Agent Orchestration:**\n",
    "\n",
    "This scenario demonstrates the **full power of Agentic RAG**:\n",
    "\n",
    "1. **Multi-Source Integration**:\n",
    "   - Internal ML knowledge for RL fundamentals\n",
    "   - Internal Finance knowledge for trading context\n",
    "   - External arXiv for latest research\n",
    "   \n",
    "2. **Intelligent Orchestration**:\n",
    "   - Agent decides which tools to use and in what order\n",
    "   - Recognizes when internal knowledge is sufficient vs. when external research is needed\n",
    "   - Synthesizes information from 3+ different sources\n",
    "   \n",
    "3. **Comprehensive Coverage**:\n",
    "   - Theory + Practice + Research\n",
    "   - Historical + Current\n",
    "   - Internal + External\n",
    "\n",
    "**This is impossible with static RAG:**\n",
    "- ‚ùå Static RAG cannot access external sources\n",
    "- ‚ùå Cannot distinguish between different types of information needs\n",
    "- ‚ùå Cannot orchestrate multiple specialized tools\n",
    "- ‚ùå Limited to what's in the vector database\n",
    "\n",
    "**Agentic RAG excels:**\n",
    "- ‚úÖ Dynamic tool selection based on query requirements\n",
    "- ‚úÖ Seamless integration of internal and external sources\n",
    "- ‚úÖ Comprehensive answers combining multiple perspectives\n",
    "- ‚úÖ Extensible to any number of specialized tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7110440",
   "metadata": {},
   "source": [
    "## Comparative Analysis: Agent Behavior Across Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea77b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE COMPARATIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = {\n",
    "    \"Scenario 1: Simple Single-Domain\": {\n",
    "        \"Query\": \"Explain gradient boosting\",\n",
    "        \"Tools Used\": \"ML knowledge only\",\n",
    "        \"Static RAG Performance\": \"Good (simple query)\",\n",
    "        \"Advantage\": \"Minimal - both work well\"\n",
    "    },\n",
    "    \"Scenario 2: Cross-Domain\": {\n",
    "        \"Query\": \"ML for stock market and portfolio management\",\n",
    "        \"Tools Used\": \"ML + Finance tools\",\n",
    "        \"Static RAG Performance\": \"May miss one domain\",\n",
    "        \"Advantage\": \"Agent guarantees coverage of both domains\"\n",
    "    },\n",
    "    \"Scenario 3: Complex Multi-Hop\": {\n",
    "        \"Query\": \"Compare RL vs traditional diversification (risk-adjusted)\",\n",
    "        \"Tools Used\": \"ML + Finance (multiple queries)\",\n",
    "        \"Static RAG Performance\": \"Likely incomplete coverage\",\n",
    "        \"Advantage\": \"Agent can decompose, retrieve iteratively, synthesize\"\n",
    "    },\n",
    "    \"Scenario 4: External Knowledge\": {\n",
    "        \"Query\": \"Latest developments in GPT-4 vs Claude 3\",\n",
    "        \"Tools Used\": \"Internet search\",\n",
    "        \"Static RAG Performance\": \"Impossible - no access to external info\",\n",
    "        \"Advantage\": \"Agent accesses current information beyond knowledge base\"\n",
    "    },\n",
    "    \"Scenario 5: Academic Research\": {\n",
    "        \"Query\": \"Recent RAG research papers and findings\",\n",
    "        \"Tools Used\": \"arXiv search + fetch\",\n",
    "        \"Static RAG Performance\": \"Impossible - no access to academic databases\",\n",
    "        \"Advantage\": \"Agent integrates cutting-edge research\"\n",
    "    },\n",
    "    \"Scenario 6: Hybrid Multi-Tool\": {\n",
    "        \"Query\": \"RL in algorithmic trading (theory + recent research)\",\n",
    "        \"Tools Used\": \"ML + Finance + arXiv (orchestrated)\",\n",
    "        \"Static RAG Performance\": \"Impossible - limited to internal KB only\",\n",
    "        \"Advantage\": \"Comprehensive synthesis of internal + external sources\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for scenario, details in summary.items():\n",
    "    print(f\"\\n{scenario}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\"*80)\n",
    "print(\"Scenarios 1-3: Agentic RAG provides better tool selection within internal KB\")\n",
    "print(\"Scenarios 4-6: Agentic RAG unlocks entirely new capabilities impossible with static RAG\")\n",
    "print(\"\\nThe extensibility to external tools is the true game-changer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb084fce",
   "metadata": {},
   "source": [
    "## Visualizing the Agentic Workflow\n",
    "\n",
    "Let's trace through the agent's decision-making for the complex query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AGENTIC RAG WORKFLOW VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "workflow = \"\"\"\n",
    "Query: \"Compare RL vs traditional diversification (risk-adjusted)\"\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 1)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"I need to understand reinforcement learning       ‚îÇ\n",
    "‚îÇ           in the context of portfolio management\"           ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Use machine_learning_knowledge tool                 ‚îÇ\n",
    "‚îÇ         Query: \"reinforcement learning for portfolio mgmt\"  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ OBSERVATION 1                                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Retrieved: RL algorithms (Q-learning, DQN, Policy Gradient) ‚îÇ\n",
    "‚îÇ            RL advantages: adaptability, non-linear learning ‚îÇ\n",
    "‚îÇ            RL challenges: non-stationarity, overfitting     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 2)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"Good, now I need information about traditional    ‚îÇ\n",
    "‚îÇ           diversification strategies and risk metrics\"      ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Use finance_knowledge tool                          ‚îÇ\n",
    "‚îÇ         Query: \"portfolio diversification and risk metrics\" ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ OBSERVATION 2                                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Retrieved: Diversification strategies (MPT, risk parity)    ‚îÇ\n",
    "‚îÇ            Sharpe Ratio = (Return - RFR) / StdDev           ‚îÇ\n",
    "‚îÇ            Maximum Drawdown = largest peak-to-trough decline‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 3)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"I have sufficient information from both domains   ‚îÇ\n",
    "‚îÇ           to perform a comprehensive comparison\"            ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Generate final answer                               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ FINAL ANSWER                                                 ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Synthesized comparison covering:                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ RL approach characteristics                              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Traditional diversification characteristics              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Sharpe ratio implications                                ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Maximum drawdown considerations                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Comparative analysis                                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\"\n",
    "\n",
    "print(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf780cd7",
   "metadata": {},
   "source": [
    "## Key Advantages of Agentic RAG\n",
    "\n",
    "### 1. **Intelligent Tool Selection**\n",
    "- Agent analyzes query semantics\n",
    "- Selects appropriate knowledge source(s)\n",
    "- More precise than embedding-based retrieval alone\n",
    "\n",
    "### 2. **Multi-Step Reasoning**\n",
    "- Can break complex queries into sub-tasks\n",
    "- Retrieves information iteratively\n",
    "- Builds comprehensive understanding step-by-step\n",
    "\n",
    "### 3. **Cross-Domain Synthesis**\n",
    "- Naturally handles queries spanning multiple domains\n",
    "- Ensures coverage of all relevant aspects\n",
    "- Better than hoping single retrieval captures everything\n",
    "\n",
    "### 4. **Adaptability**\n",
    "- Can adjust strategy based on retrieved information\n",
    "- Can make follow-up queries if needed\n",
    "- Dynamic rather than fixed retrieval path\n",
    "\n",
    "### 5. **Transparency**\n",
    "- Reasoning process is visible (with verbose=True)\n",
    "- Can see which tools were used and why\n",
    "- Easier to debug and understand system behavior\n",
    "\n",
    "### 6. **Extensibility**\n",
    "- Easy to add new tools (web search, calculators, APIs)\n",
    "- Agent learns to use them automatically\n",
    "- Scales better than monolithic systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00086647",
   "metadata": {},
   "source": [
    "## When to Use Agentic RAG\n",
    "\n",
    "### ‚úÖ Use Agentic RAG when:\n",
    "1. **Multiple Knowledge Sources**: You have distinct, specialized knowledge bases\n",
    "2. **Complex Queries**: Questions require multi-step reasoning or synthesis\n",
    "3. **Cross-Domain**: Queries span multiple topics or domains\n",
    "4. **Dynamic Needs**: Need to adapt retrieval strategy based on query\n",
    "5. **Interpretability**: Want to understand the reasoning process\n",
    "6. **Tool Integration**: Need to combine retrieval with other tools (calculators, APIs)\n",
    "\n",
    "### ‚ö†Ô∏è Consider Static RAG when:\n",
    "1. **Simple Queries**: Straightforward single-topic questions\n",
    "2. **Speed Critical**: Need fastest possible response (agent adds latency)\n",
    "3. **Cost Sensitive**: Agent makes multiple LLM calls (higher cost)\n",
    "4. **Single Source**: Only one homogeneous knowledge base\n",
    "5. **Predictable Patterns**: All queries follow similar pattern\n",
    "\n",
    "### üí° Hybrid Approach:\n",
    "- Use static RAG for simple, common queries\n",
    "- Route complex queries to agentic system\n",
    "- Best of both worlds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7ec3f",
   "metadata": {},
   "source": [
    "## Limitations and Considerations\n",
    "\n",
    "### Challenges with Agentic RAG:\n",
    "\n",
    "1. **Latency**\n",
    "   - Multiple LLM calls (reasoning + tool use)\n",
    "   - Slower than single-pass retrieval\n",
    "   - May require optimization for production\n",
    "\n",
    "2. **Cost**\n",
    "   - More LLM token usage\n",
    "   - Multiple embedding operations\n",
    "   - Can be 3-5x more expensive per query\n",
    "\n",
    "3. **Complexity**\n",
    "   - More moving parts\n",
    "   - Harder to debug when things go wrong\n",
    "   - Requires careful prompt engineering\n",
    "\n",
    "4. **Reliability**\n",
    "   - Agent might not always choose optimal tool\n",
    "   - Can get stuck in loops (max_iterations needed)\n",
    "   - More failure modes than static systems\n",
    "\n",
    "5. **Token Limits**\n",
    "   - Reasoning traces consume context window\n",
    "   - May need careful management of conversation history\n",
    "\n",
    "### Mitigation Strategies:\n",
    "- Use caching for common queries\n",
    "- Implement query classification (route simple queries to static RAG)\n",
    "- Optimize tool descriptions for better selection\n",
    "- Monitor and limit max_iterations\n",
    "- Implement fallbacks for agent failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6f3d8",
   "metadata": {},
   "source": [
    "## Extensions and Advanced Patterns\n",
    "\n",
    "### 1. **Add More Tools**\n",
    "```python\n",
    "# Web search tool\n",
    "web_search_tool = QueryEngineTool(...)\n",
    "\n",
    "# Calculator tool for numerical operations\n",
    "calculator_tool = FunctionTool.from_defaults(...)\n",
    "\n",
    "# External API tool\n",
    "api_tool = QueryEngineTool(...)\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool, web_search_tool, calculator_tool, api_tool],\n",
    "    llm=azure_llm\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. **Sub-Agents Pattern**\n",
    "Create specialized agents for each domain:\n",
    "```python\n",
    "ml_agent = ReActAgent.from_tools([ml_tool_1, ml_tool_2], ...)\n",
    "finance_agent = ReActAgent.from_tools([finance_tool_1, finance_tool_2], ...)\n",
    "\n",
    "# Meta-agent that delegates to sub-agents\n",
    "meta_agent = ReActAgent.from_tools(\n",
    "    tools=[ml_agent_tool, finance_agent_tool],\n",
    "    llm=azure_llm\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. **Memory-Augmented Agents**\n",
    "```python\n",
    "# Add conversation memory\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3000)\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool],\n",
    "    llm=azure_llm,\n",
    "    memory=memory  # Maintains context across queries\n",
    ")\n",
    "```\n",
    "\n",
    "### 4. **Custom Tool Creation**\n",
    "```python\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def calculate_sharpe_ratio(returns: List[float], risk_free_rate: float) -> float:\n",
    "    \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "    # Implementation\n",
    "    pass\n",
    "\n",
    "sharpe_tool = FunctionTool.from_defaults(fn=calculate_sharpe_ratio)\n",
    "```\n",
    "\n",
    "### 5. **Hybrid Routing**\n",
    "```python\n",
    "def smart_query(query: str):\n",
    "    # Classify query complexity\n",
    "    if is_simple(query):\n",
    "        return static_query_engine.query(query)\n",
    "    else:\n",
    "        return agent.chat(query)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dec70",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Agentic RAG represents a paradigm shift** from passive retrieval to active reasoning\n",
    "\n",
    "2. **The ReAct pattern** (Reasoning + Acting) enables systematic multi-step information gathering\n",
    "\n",
    "3. **Tool-based architecture** makes systems modular and extensible to **any information source**\n",
    "\n",
    "4. **Agent's planning capability** ensures comprehensive coverage of complex queries\n",
    "\n",
    "5. **External tool integration** (internet search, arXiv, APIs) unlocks capabilities impossible with static RAG\n",
    "\n",
    "6. **Trade-offs exist**: Higher latency and cost vs. better handling of complex queries and access to external information\n",
    "\n",
    "7. **Best practice**: Use hybrid approach‚Äîstatic RAG for simple queries, agentic for complex and external information needs\n",
    "\n",
    "### When Agentic RAG Shines\n",
    "- ‚úÖ Cross-domain questions requiring multiple knowledge bases\n",
    "- ‚úÖ Multi-hop reasoning required\n",
    "- ‚úÖ Multiple specialized knowledge sources\n",
    "- ‚úÖ Need for interpretable reasoning\n",
    "- ‚úÖ Integration with external tools/APIs\n",
    "- ‚úÖ **Current information beyond knowledge base cutoff**\n",
    "- ‚úÖ **Academic research and literature reviews**\n",
    "- ‚úÖ **Hybrid internal-external information synthesis**\n",
    "\n",
    "### Tools Demonstrated in This Notebook\n",
    "\n",
    "**Internal Knowledge:**\n",
    "1. Machine Learning concepts\n",
    "2. Finance and trading knowledge\n",
    "\n",
    "**External Knowledge:**\n",
    "3. Internet search (DuckDuckGo) - current information\n",
    "4. arXiv search - academic papers\n",
    "5. arXiv fetch - specific paper details\n",
    "\n",
    "**Extensible to:**\n",
    "- Any API (weather, stock prices, news, etc.)\n",
    "- Databases and data warehouses\n",
    "- Custom calculators and processors\n",
    "- Other AI models and services\n",
    "\n",
    "### The Future of RAG\n",
    "\n",
    "As LLM reasoning capabilities improve and costs decrease, **agentic approaches will become increasingly practical**. The ability to:\n",
    "- Plan retrieval strategies dynamically\n",
    "- Adapt to retrieved information\n",
    "- Synthesize from multiple sources (internal + external)\n",
    "- Integrate diverse tools seamlessly\n",
    "- Access current information and research\n",
    "\n",
    "...represents the next evolution of RAG systems.\n",
    "\n",
    "### Impact of External Tools\n",
    "\n",
    "The addition of internet search and arXiv integration demonstrates that **Agentic RAG is not limited by knowledge base boundaries**:\n",
    "\n",
    "- **Static RAG**: Constrained to pre-indexed documents\n",
    "- **Agentic RAG**: Access to the entire internet, academic databases, APIs, and more\n",
    "\n",
    "This fundamentally changes what's possible:\n",
    "- No need to constantly update internal knowledge bases\n",
    "- Always have access to latest information\n",
    "- Can verify facts against multiple sources\n",
    "- Bridge internal knowledge with external research\n",
    "\n",
    "### Further Exploration\n",
    "- Experiment with different agent types (OpenAI Function Calling Agent, Structured Planning Agent)\n",
    "- Add custom tools for your domain (calculators, databases, proprietary APIs)\n",
    "- Integrate more external sources (Google Scholar, Wikipedia, news APIs)\n",
    "- Implement agent memory for multi-turn conversations\n",
    "- Explore sub-agent hierarchies for very complex domains\n",
    "- Build evaluation frameworks to measure agent decision quality\n",
    "- Add authentication for accessing private/proprietary tools\n",
    "- Implement caching strategies for expensive external calls"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
