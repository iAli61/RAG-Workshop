{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc2a898",
   "metadata": {},
   "source": [
    "# Demo #8: Agentic RAG - Autonomous Query Planning and Tool Selection\n",
    "\n",
    "## Objective\n",
    "Demonstrate an autonomous agent that dynamically plans retrieval strategies and selects appropriate tools to answer complex queries.\n",
    "\n",
    "## Core Concepts\n",
    "- **Agentic workflow**: Thought ‚Üí Action ‚Üí Observation loop (ReAct framework)\n",
    "- **Dynamic tool selection**: Agent chooses which knowledge base to query\n",
    "- **Multi-step reasoning**: Agent decomposes complex questions into sub-tasks\n",
    "- **Query decomposition and planning**: Autonomous strategy formulation\n",
    "\n",
    "## What is Agentic RAG?\n",
    "\n",
    "Traditional RAG is **passive**: it retrieves from a single, fixed knowledge base and generates an answer.\n",
    "\n",
    "**Agentic RAG** is **active**: it uses an LLM-powered agent that:\n",
    "1. **Analyzes** the query to understand requirements\n",
    "2. **Plans** which knowledge sources to consult\n",
    "3. **Executes** multi-step retrieval strategies\n",
    "4. **Adapts** based on retrieved information\n",
    "5. **Synthesizes** information from multiple sources\n",
    "\n",
    "### Static RAG vs. Agentic RAG\n",
    "\n",
    "**Static RAG:**\n",
    "```\n",
    "Query ‚Üí Single Vector DB ‚Üí Retrieve Top-K ‚Üí Generate\n",
    "```\n",
    "- ‚ùå No query analysis\n",
    "- ‚ùå Fixed retrieval strategy\n",
    "- ‚ùå Single knowledge source\n",
    "- ‚ùå No multi-hop reasoning\n",
    "\n",
    "**Agentic RAG:**\n",
    "```\n",
    "Query ‚Üí Agent Analyzes\n",
    "          ‚Üì\n",
    "    Plans retrieval strategy\n",
    "          ‚Üì\n",
    "    Selects Tool 1 ‚Üí Retrieve ‚Üí Observation\n",
    "          ‚Üì\n",
    "    Needs more info?\n",
    "          ‚Üì\n",
    "    Selects Tool 2 ‚Üí Retrieve ‚Üí Observation\n",
    "          ‚Üì\n",
    "    Synthesize all observations ‚Üí Generate\n",
    "```\n",
    "- ‚úÖ Intelligent query understanding\n",
    "- ‚úÖ Dynamic strategy selection\n",
    "- ‚úÖ Multiple knowledge sources\n",
    "- ‚úÖ Multi-hop reasoning\n",
    "\n",
    "## ReAct Framework\n",
    "\n",
    "The agent uses the **ReAct** (Reasoning + Acting) pattern:\n",
    "\n",
    "```\n",
    "Loop:\n",
    "  1. Thought: \"I need information about X\"\n",
    "  2. Action: Use tool Y with query Z\n",
    "  3. Observation: Retrieved information\n",
    "  4. Thought: \"This partially answers the question, but I need more about A\"\n",
    "  5. Action: Use tool W with query B\n",
    "  6. Observation: Additional information\n",
    "  7. Thought: \"Now I have enough information\"\n",
    "  8. Final Answer: Synthesized response\n",
    "```\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "1. **Cross-domain queries**: \"How can ML improve financial portfolio management?\"\n",
    "   - Queries ML knowledge base\n",
    "   - Queries finance knowledge base\n",
    "   - Synthesizes both\n",
    "\n",
    "2. **Multi-hop reasoning**: \"Compare X vs. Y considering factors A, B, and C\"\n",
    "   - Retrieves info about X\n",
    "   - Retrieves info about Y\n",
    "   - Retrieves info about factors A, B, C\n",
    "   - Performs comparative analysis\n",
    "\n",
    "3. **Iterative refinement**: Start broad, drill down into specifics\n",
    "   - Initial query gets overview\n",
    "   - Follow-up queries get details\n",
    "   - Builds comprehensive understanding\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "Complex Query\n",
    "  ‚Üì\n",
    "Agent receives query\n",
    "  ‚Üì\n",
    "Agent reasons: \"This requires info from ML and Finance domains\"\n",
    "  ‚Üì\n",
    "Action 1: Query ML knowledge base\n",
    "  ‚Üì\n",
    "Observation 1: Retrieved ML context\n",
    "  ‚Üì\n",
    "Agent reasons: \"Good, now I need financial perspective\"\n",
    "  ‚Üì\n",
    "Action 2: Query Finance knowledge base\n",
    "  ‚Üì\n",
    "Observation 2: Retrieved Finance context\n",
    "  ‚Üì\n",
    "Agent reasons: \"I have sufficient information\"\n",
    "  ‚Üì\n",
    "Final Answer: Synthesized response combining both domains\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2c0d9",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies and Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell if packages are not already installed\n",
    "# !pip install llama-index llama-index-llms-azure-openai llama-index-embeddings-azure-openai\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify Azure OpenAI credentials\n",
    "required_vars = [\n",
    "    'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_ENDPOINT',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'AZURE_OPENAI_DEPLOYMENT_NAME',\n",
    "    'AZURE_OPENAI_EMBEDDING_DEPLOYMENT'\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"\\nPlease create a .env file with:\")\n",
    "    for var in missing_vars:\n",
    "        print(f\"{var}=<your_value>\")\n",
    "else:\n",
    "    print(\"‚úÖ All required environment variables are set\")\n",
    "    print(f\"   Endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "    print(f\"   Deployment: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}\")\n",
    "    print(f\"   Embedding: {os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68fddd",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Azure OpenAI Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff514f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Initialize Azure OpenAI LLM\n",
    "azure_llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    temperature=0.0  # Deterministic for consistent comparisons\n",
    ")\n",
    "\n",
    "# Initialize Azure OpenAI Embedding Model\n",
    "azure_embed = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    ")\n",
    "\n",
    "# Set global defaults\n",
    "Settings.llm = azure_llm\n",
    "Settings.embed_model = azure_embed\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI components initialized\")\n",
    "print(f\"   LLM: {azure_llm.model}\")\n",
    "print(f\"   Embeddings: {azure_embed.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3ac24",
   "metadata": {},
   "source": [
    "## Step 2: Load and Index Machine Learning Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Define paths\n",
    "ml_data_path = \"./data/ml_concepts\"\n",
    "\n",
    "print(\"üìÅ Loading Machine Learning documents...\")\n",
    "\n",
    "# Load ML documents\n",
    "ml_documents = SimpleDirectoryReader(\n",
    "    input_dir=ml_data_path,\n",
    "    recursive=False,\n",
    "    required_exts=[\".md\"]\n",
    ").load_data()\n",
    "\n",
    "print(f\"   Loaded {len(ml_documents)} ML documents\")\n",
    "for doc in ml_documents:\n",
    "    print(f\"   - {doc.metadata.get('file_name', 'Unknown')}\")\n",
    "\n",
    "# Parse into chunks\n",
    "parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "ml_nodes = parser.get_nodes_from_documents(ml_documents)\n",
    "print(f\"\\n   Parsed into {len(ml_nodes)} chunks\")\n",
    "\n",
    "# Create vector index\n",
    "print(\"\\nüîç Creating ML vector index...\")\n",
    "ml_index = VectorStoreIndex(ml_nodes, embed_model=azure_embed)\n",
    "print(\"‚úÖ ML index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42338c",
   "metadata": {},
   "source": [
    "## Step 3: Load and Index Finance Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fccbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "finance_data_path = \"./data/finance_docs\"\n",
    "\n",
    "print(\"üìÅ Loading Finance documents...\")\n",
    "\n",
    "# Load Finance documents\n",
    "finance_documents = SimpleDirectoryReader(\n",
    "    input_dir=finance_data_path,\n",
    "    recursive=False,\n",
    "    required_exts=[\".md\"]\n",
    ").load_data()\n",
    "\n",
    "print(f\"   Loaded {len(finance_documents)} Finance documents\")\n",
    "for doc in finance_documents:\n",
    "    print(f\"   - {doc.metadata.get('file_name', 'Unknown')}\")\n",
    "\n",
    "# Parse into chunks\n",
    "finance_nodes = parser.get_nodes_from_documents(finance_documents)\n",
    "print(f\"\\n   Parsed into {len(finance_nodes)} chunks\")\n",
    "\n",
    "# Create vector index\n",
    "print(\"\\nüîç Creating Finance vector index...\")\n",
    "finance_index = VectorStoreIndex(finance_nodes, embed_model=azure_embed)\n",
    "print(\"‚úÖ Finance index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75ea28",
   "metadata": {},
   "source": [
    "## Step 4: Create Query Engine Tools for Agent\n",
    "\n",
    "We wrap each knowledge base in a tool that the agent can use. Each tool has:\n",
    "- **name**: Identifier for the tool\n",
    "- **description**: Helps the agent decide when to use this tool\n",
    "- **query_engine**: The actual retrieval system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbedb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# Create query engines\n",
    "ml_query_engine = ml_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "finance_query_engine = finance_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "# Wrap in tools with descriptive metadata\n",
    "ml_tool = QueryEngineTool(\n",
    "    query_engine=ml_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"machine_learning_knowledge\",\n",
    "        description=(\n",
    "            \"Provides expert knowledge about machine learning algorithms, concepts, and techniques. \"\n",
    "            \"Use this tool for questions about: neural networks, gradient boosting, random forests, \"\n",
    "            \"support vector machines, k-means clustering, deep learning, reinforcement learning, \"\n",
    "            \"model training, optimization, and ML theory.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "finance_tool = QueryEngineTool(\n",
    "    query_engine=finance_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"finance_knowledge\",\n",
    "        description=(\n",
    "            \"Provides information about financial concepts, investment strategies, and market analysis. \"\n",
    "            \"Use this tool for questions about: portfolio management, diversification, risk management, \"\n",
    "            \"quantitative trading, technical analysis, market indicators, investment strategies, \"\n",
    "            \"and financial markets.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Query engine tools created:\")\n",
    "print(f\"   1. {ml_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {ml_tool.metadata.description[:80]}...\")\n",
    "print(f\"\\n   2. {finance_tool.metadata.name}\")\n",
    "print(f\"      ‚Üí {finance_tool.metadata.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eff0e5",
   "metadata": {},
   "source": [
    "## Step 5: Create ReAct Agent\n",
    "\n",
    "The **ReActAgent** implements the Reasoning + Acting pattern:\n",
    "- **Reasoning**: Agent thinks about what information it needs\n",
    "- **Acting**: Agent uses tools to gather information\n",
    "- **Loop**: Continues until it has enough information to answer\n",
    "\n",
    "We enable `verbose=True` to see the agent's internal reasoning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90110aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "# Create ReAct agent with both tools\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool],\n",
    "    llm=azure_llm,\n",
    "    verbose=True,  # Show reasoning process\n",
    "    max_iterations=5  # Prevent infinite loops\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ReAct Agent initialized\")\n",
    "print(f\"   Available tools: {len(agent.get_tools())}\")\n",
    "print(f\"   Max iterations: 5\")\n",
    "print(f\"   Verbose: True (will show reasoning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd99ad3",
   "metadata": {},
   "source": [
    "## Step 6: Create Static RAG Baseline for Comparison\n",
    "\n",
    "To demonstrate the advantages of Agentic RAG, we'll create a static RAG system that simply combines both knowledge bases into one index. This represents the traditional approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Creating static RAG baseline (combined index)...\")\n",
    "\n",
    "# Combine all nodes\n",
    "combined_nodes = ml_nodes + finance_nodes\n",
    "print(f\"   Combined {len(combined_nodes)} chunks from both domains\")\n",
    "\n",
    "# Create combined index\n",
    "combined_index = VectorStoreIndex(combined_nodes, embed_model=azure_embed)\n",
    "static_query_engine = combined_index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Static RAG baseline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43727cc8",
   "metadata": {},
   "source": [
    "## Test Scenario 1: Simple Single-Domain Query\n",
    "\n",
    "**Query**: \"Explain gradient boosting.\"\n",
    "\n",
    "This is a straightforward ML question. The agent should:\n",
    "1. Identify that this is about machine learning\n",
    "2. Use the ML knowledge tool\n",
    "3. Retrieve relevant information\n",
    "4. Provide an answer\n",
    "\n",
    "Expected: Agent uses only the ML tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be680d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 1: Simple Single-Domain Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_1 = \"Explain gradient boosting.\"\n",
    "print(f\"\\nüìù Query: {query_1}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with tool selection):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent (verbose=True will show reasoning)\n",
    "agent_response_1 = agent.chat(query_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_1 = static_query_engine.query(query_1)\n",
    "print(static_response_1.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_1.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73c5e7",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 1\n",
    "\n",
    "**What to observe:**\n",
    "- Agent's reasoning process (Thought ‚Üí Action ‚Üí Observation)\n",
    "- Tool selection (should choose ML tool)\n",
    "- Both approaches should provide good answers for single-domain queries\n",
    "- Agent might be more targeted in tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c573d7",
   "metadata": {},
   "source": [
    "## Test Scenario 2: Cross-Domain Query\n",
    "\n",
    "**Query**: \"How can machine learning be applied to stock market prediction and portfolio management?\"\n",
    "\n",
    "This requires information from BOTH domains:\n",
    "- **ML**: How ML models work, what algorithms are suitable\n",
    "- **Finance**: Portfolio management concepts, market dynamics\n",
    "\n",
    "Expected behavior:\n",
    "- Agent should recognize the cross-domain nature\n",
    "- Use ML tool to get ML information\n",
    "- Use Finance tool to get financial context\n",
    "- Synthesize information from both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 2: Cross-Domain Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_2 = \"How can machine learning be applied to stock market prediction and portfolio management?\"\n",
    "print(f\"\\nüìù Query: {query_2}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with multi-tool usage):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use both tools\n",
    "agent_response_2 = agent.chat(query_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_2.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_2 = static_query_engine.query(query_2)\n",
    "print(static_response_2.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_2.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a649ccc",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 2\n",
    "\n",
    "**Key differences:**\n",
    "\n",
    "**Agentic RAG:**\n",
    "- ‚úÖ Explicitly queries both ML and Finance tools\n",
    "- ‚úÖ Systematic retrieval from each domain\n",
    "- ‚úÖ Guaranteed coverage of both aspects\n",
    "- ‚úÖ Clear reasoning trail showing multi-step process\n",
    "\n",
    "**Static RAG:**\n",
    "- ‚ö†Ô∏è Relies on vector similarity alone\n",
    "- ‚ö†Ô∏è May miss one domain if embedding similarity is skewed\n",
    "- ‚ö†Ô∏è Top-3 chunks might all come from one domain\n",
    "- ‚ö†Ô∏è No guarantee of balanced coverage\n",
    "\n",
    "The agent's ability to **plan** and **execute** multi-step retrieval ensures comprehensive answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fba8b9",
   "metadata": {},
   "source": [
    "## Test Scenario 3: Complex Multi-Hop Query\n",
    "\n",
    "**Query**: \"Compare the risk-adjusted returns of portfolio strategies using reinforcement learning versus traditional diversification. Consider both the Sharpe ratio and maximum drawdown.\"\n",
    "\n",
    "This is a complex query requiring:\n",
    "1. **Reinforcement learning** knowledge (ML domain)\n",
    "2. **Portfolio diversification** strategies (Finance domain)\n",
    "3. **Risk metrics** like Sharpe ratio and max drawdown (Finance domain)\n",
    "4. **Synthesis** of ML approaches to finance problems\n",
    "\n",
    "Expected: Agent should:\n",
    "- Break down into sub-questions\n",
    "- Query ML tool for RL concepts\n",
    "- Query Finance tool for diversification strategies\n",
    "- Query Finance tool again for risk metrics\n",
    "- Perform comparative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22341716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SCENARIO 3: Complex Multi-Hop Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query_3 = (\n",
    "    \"Compare the risk-adjusted returns of portfolio strategies using reinforcement learning \"\n",
    "    \"versus traditional diversification. Consider both the Sharpe ratio and maximum drawdown.\"\n",
    ")\n",
    "print(f\"\\nüìù Query: {query_3}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENTIC RAG (with multi-step reasoning):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run agent - should use multiple queries across tools\n",
    "agent_response_3 = agent.chat(query_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT'S FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(agent_response_3.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with static RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIC RAG (combined index):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "static_response_3 = static_query_engine.query(query_3)\n",
    "print(static_response_3.response)\n",
    "\n",
    "# Show retrieved sources\n",
    "print(\"\\nüìö Sources used:\")\n",
    "for i, node in enumerate(static_response_3.source_nodes, 1):\n",
    "    filename = node.metadata.get('file_name', 'Unknown')\n",
    "    score = node.score\n",
    "    print(f\"   {i}. {filename} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fe80f",
   "metadata": {},
   "source": [
    "### Analysis: Scenario 3\n",
    "\n",
    "**Agent's advantages become clear:**\n",
    "\n",
    "1. **Decomposition**: Agent breaks complex query into manageable sub-questions\n",
    "2. **Strategic retrieval**: Queries specific tools for specific information\n",
    "3. **Iterative refinement**: Can make follow-up queries if initial information is insufficient\n",
    "4. **Synthesis**: Combines information from multiple sources coherently\n",
    "\n",
    "**Static RAG limitations:**\n",
    "- Must rely on single query embedding matching multiple concepts\n",
    "- Top-K retrieval might miss important aspects\n",
    "- No ability to \"realize\" information is missing and query again\n",
    "- Less systematic coverage of complex multi-part questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7110440",
   "metadata": {},
   "source": [
    "## Comparative Analysis: Agent Behavior Across Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea77b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARATIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = {\n",
    "    \"Scenario 1: Simple Single-Domain\": {\n",
    "        \"Query\": \"Explain gradient boosting\",\n",
    "        \"Expected Agent Behavior\": \"Use ML tool only\",\n",
    "        \"Static RAG Performance\": \"Good (simple query)\",\n",
    "        \"Advantage\": \"Minimal - both work well\"\n",
    "    },\n",
    "    \"Scenario 2: Cross-Domain\": {\n",
    "        \"Query\": \"ML for stock market and portfolio management\",\n",
    "        \"Expected Agent Behavior\": \"Use both ML and Finance tools\",\n",
    "        \"Static RAG Performance\": \"May miss one domain\",\n",
    "        \"Advantage\": \"Agent guarantees coverage of both domains\"\n",
    "    },\n",
    "    \"Scenario 3: Complex Multi-Hop\": {\n",
    "        \"Query\": \"Compare RL vs traditional diversification (risk-adjusted)\",\n",
    "        \"Expected Agent Behavior\": \"Multiple queries across tools, synthesis\",\n",
    "        \"Static RAG Performance\": \"Likely incomplete coverage\",\n",
    "        \"Advantage\": \"Agent can decompose, retrieve iteratively, synthesize\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for scenario, details in summary.items():\n",
    "    print(f\"\\n{scenario}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb084fce",
   "metadata": {},
   "source": [
    "## Visualizing the Agentic Workflow\n",
    "\n",
    "Let's trace through the agent's decision-making for the complex query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AGENTIC RAG WORKFLOW VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "workflow = \"\"\"\n",
    "Query: \"Compare RL vs traditional diversification (risk-adjusted)\"\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 1)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"I need to understand reinforcement learning       ‚îÇ\n",
    "‚îÇ           in the context of portfolio management\"           ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Use machine_learning_knowledge tool                 ‚îÇ\n",
    "‚îÇ         Query: \"reinforcement learning for portfolio mgmt\"  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ OBSERVATION 1                                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Retrieved: RL algorithms (Q-learning, DQN, Policy Gradient) ‚îÇ\n",
    "‚îÇ            RL advantages: adaptability, non-linear learning ‚îÇ\n",
    "‚îÇ            RL challenges: non-stationarity, overfitting     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 2)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"Good, now I need information about traditional    ‚îÇ\n",
    "‚îÇ           diversification strategies and risk metrics\"      ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Use finance_knowledge tool                          ‚îÇ\n",
    "‚îÇ         Query: \"portfolio diversification and risk metrics\" ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ OBSERVATION 2                                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Retrieved: Diversification strategies (MPT, risk parity)    ‚îÇ\n",
    "‚îÇ            Sharpe Ratio = (Return - RFR) / StdDev           ‚îÇ\n",
    "‚îÇ            Maximum Drawdown = largest peak-to-trough decline‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ AGENT REASONING (Iteration 3)                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Thought: \"I have sufficient information from both domains   ‚îÇ\n",
    "‚îÇ           to perform a comprehensive comparison\"            ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ Action: Generate final answer                               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ FINAL ANSWER                                                 ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Synthesized comparison covering:                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ RL approach characteristics                              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Traditional diversification characteristics              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Sharpe ratio implications                                ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Maximum drawdown considerations                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Comparative analysis                                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\"\n",
    "\n",
    "print(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf780cd7",
   "metadata": {},
   "source": [
    "## Key Advantages of Agentic RAG\n",
    "\n",
    "### 1. **Intelligent Tool Selection**\n",
    "- Agent analyzes query semantics\n",
    "- Selects appropriate knowledge source(s)\n",
    "- More precise than embedding-based retrieval alone\n",
    "\n",
    "### 2. **Multi-Step Reasoning**\n",
    "- Can break complex queries into sub-tasks\n",
    "- Retrieves information iteratively\n",
    "- Builds comprehensive understanding step-by-step\n",
    "\n",
    "### 3. **Cross-Domain Synthesis**\n",
    "- Naturally handles queries spanning multiple domains\n",
    "- Ensures coverage of all relevant aspects\n",
    "- Better than hoping single retrieval captures everything\n",
    "\n",
    "### 4. **Adaptability**\n",
    "- Can adjust strategy based on retrieved information\n",
    "- Can make follow-up queries if needed\n",
    "- Dynamic rather than fixed retrieval path\n",
    "\n",
    "### 5. **Transparency**\n",
    "- Reasoning process is visible (with verbose=True)\n",
    "- Can see which tools were used and why\n",
    "- Easier to debug and understand system behavior\n",
    "\n",
    "### 6. **Extensibility**\n",
    "- Easy to add new tools (web search, calculators, APIs)\n",
    "- Agent learns to use them automatically\n",
    "- Scales better than monolithic systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00086647",
   "metadata": {},
   "source": [
    "## When to Use Agentic RAG\n",
    "\n",
    "### ‚úÖ Use Agentic RAG when:\n",
    "1. **Multiple Knowledge Sources**: You have distinct, specialized knowledge bases\n",
    "2. **Complex Queries**: Questions require multi-step reasoning or synthesis\n",
    "3. **Cross-Domain**: Queries span multiple topics or domains\n",
    "4. **Dynamic Needs**: Need to adapt retrieval strategy based on query\n",
    "5. **Interpretability**: Want to understand the reasoning process\n",
    "6. **Tool Integration**: Need to combine retrieval with other tools (calculators, APIs)\n",
    "\n",
    "### ‚ö†Ô∏è Consider Static RAG when:\n",
    "1. **Simple Queries**: Straightforward single-topic questions\n",
    "2. **Speed Critical**: Need fastest possible response (agent adds latency)\n",
    "3. **Cost Sensitive**: Agent makes multiple LLM calls (higher cost)\n",
    "4. **Single Source**: Only one homogeneous knowledge base\n",
    "5. **Predictable Patterns**: All queries follow similar pattern\n",
    "\n",
    "### üí° Hybrid Approach:\n",
    "- Use static RAG for simple, common queries\n",
    "- Route complex queries to agentic system\n",
    "- Best of both worlds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7ec3f",
   "metadata": {},
   "source": [
    "## Limitations and Considerations\n",
    "\n",
    "### Challenges with Agentic RAG:\n",
    "\n",
    "1. **Latency**\n",
    "   - Multiple LLM calls (reasoning + tool use)\n",
    "   - Slower than single-pass retrieval\n",
    "   - May require optimization for production\n",
    "\n",
    "2. **Cost**\n",
    "   - More LLM token usage\n",
    "   - Multiple embedding operations\n",
    "   - Can be 3-5x more expensive per query\n",
    "\n",
    "3. **Complexity**\n",
    "   - More moving parts\n",
    "   - Harder to debug when things go wrong\n",
    "   - Requires careful prompt engineering\n",
    "\n",
    "4. **Reliability**\n",
    "   - Agent might not always choose optimal tool\n",
    "   - Can get stuck in loops (max_iterations needed)\n",
    "   - More failure modes than static systems\n",
    "\n",
    "5. **Token Limits**\n",
    "   - Reasoning traces consume context window\n",
    "   - May need careful management of conversation history\n",
    "\n",
    "### Mitigation Strategies:\n",
    "- Use caching for common queries\n",
    "- Implement query classification (route simple queries to static RAG)\n",
    "- Optimize tool descriptions for better selection\n",
    "- Monitor and limit max_iterations\n",
    "- Implement fallbacks for agent failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6f3d8",
   "metadata": {},
   "source": [
    "## Extensions and Advanced Patterns\n",
    "\n",
    "### 1. **Add More Tools**\n",
    "```python\n",
    "# Web search tool\n",
    "web_search_tool = QueryEngineTool(...)\n",
    "\n",
    "# Calculator tool for numerical operations\n",
    "calculator_tool = FunctionTool.from_defaults(...)\n",
    "\n",
    "# External API tool\n",
    "api_tool = QueryEngineTool(...)\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool, web_search_tool, calculator_tool, api_tool],\n",
    "    llm=azure_llm\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. **Sub-Agents Pattern**\n",
    "Create specialized agents for each domain:\n",
    "```python\n",
    "ml_agent = ReActAgent.from_tools([ml_tool_1, ml_tool_2], ...)\n",
    "finance_agent = ReActAgent.from_tools([finance_tool_1, finance_tool_2], ...)\n",
    "\n",
    "# Meta-agent that delegates to sub-agents\n",
    "meta_agent = ReActAgent.from_tools(\n",
    "    tools=[ml_agent_tool, finance_agent_tool],\n",
    "    llm=azure_llm\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. **Memory-Augmented Agents**\n",
    "```python\n",
    "# Add conversation memory\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3000)\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[ml_tool, finance_tool],\n",
    "    llm=azure_llm,\n",
    "    memory=memory  # Maintains context across queries\n",
    ")\n",
    "```\n",
    "\n",
    "### 4. **Custom Tool Creation**\n",
    "```python\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def calculate_sharpe_ratio(returns: List[float], risk_free_rate: float) -> float:\n",
    "    \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "    # Implementation\n",
    "    pass\n",
    "\n",
    "sharpe_tool = FunctionTool.from_defaults(fn=calculate_sharpe_ratio)\n",
    "```\n",
    "\n",
    "### 5. **Hybrid Routing**\n",
    "```python\n",
    "def smart_query(query: str):\n",
    "    # Classify query complexity\n",
    "    if is_simple(query):\n",
    "        return static_query_engine.query(query)\n",
    "    else:\n",
    "        return agent.chat(query)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dec70",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Agentic RAG represents a paradigm shift** from passive retrieval to active reasoning\n",
    "\n",
    "2. **The ReAct pattern** (Reasoning + Acting) enables systematic multi-step information gathering\n",
    "\n",
    "3. **Tool-based architecture** makes systems modular and extensible\n",
    "\n",
    "4. **Agent's planning capability** ensures comprehensive coverage of complex queries\n",
    "\n",
    "5. **Trade-offs exist**: Higher latency and cost vs. better handling of complex queries\n",
    "\n",
    "6. **Best practice**: Use hybrid approach‚Äîstatic RAG for simple queries, agentic for complex\n",
    "\n",
    "### When Agentic RAG Shines\n",
    "- ‚úÖ Cross-domain questions\n",
    "- ‚úÖ Multi-hop reasoning required\n",
    "- ‚úÖ Multiple specialized knowledge sources\n",
    "- ‚úÖ Need for interpretable reasoning\n",
    "- ‚úÖ Integration with external tools/APIs\n",
    "\n",
    "### The Future of RAG\n",
    "As LLM reasoning capabilities improve and costs decrease, **agentic approaches will become increasingly practical**. The ability to:\n",
    "- Plan retrieval strategies\n",
    "- Adapt to retrieved information\n",
    "- Synthesize from multiple sources\n",
    "- Integrate diverse tools\n",
    "\n",
    "...represents the next evolution of RAG systems.\n",
    "\n",
    "### Further Exploration\n",
    "- Experiment with different agent types (OpenAI Function Calling Agent, Structured Planning Agent)\n",
    "- Add custom tools for your domain\n",
    "- Implement agent memory for multi-turn conversations\n",
    "- Explore sub-agent hierarchies for very complex domains\n",
    "- Build evaluation frameworks to measure agent decision quality"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
