{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433fdd81",
   "metadata": {},
   "source": [
    "# Demo #8: Agentic RAG - Autonomous Query Planning and Tool Selection\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **Agentic RAG**, where an autonomous agent dynamically plans retrieval strategies, selects appropriate tools, and performs multi-step reasoning to answer complex queries.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Agentic Workflow**: Thought â†’ Action â†’ Observation loop (ReAct pattern)\n",
    "2. **Dynamic Tool Selection**: Agent chooses the right tool(s) for each query\n",
    "3. **Multi-Step Reasoning**: Breaks complex queries into sub-tasks\n",
    "4. **Tool Orchestration**: Coordinates multiple knowledge sources and external APIs\n",
    "\n",
    "### The ReAct Agent Architecture\n",
    "\n",
    "```\n",
    "Complex Query\n",
    "    â†“\n",
    "Agent Analyzes â†’ Plans Sub-Tasks\n",
    "    â†“\n",
    "For Each Sub-Task:\n",
    "    â”œâ”€ Thought: \"I need information about X\"\n",
    "    â”œâ”€ Action: Select tool and execute\n",
    "    â”‚   â”œâ”€ ML Knowledge Base\n",
    "    â”‚   â”œâ”€ Finance Knowledge Base\n",
    "    â”‚   â”œâ”€ Internet Search (DuckDuckGo)\n",
    "    â”‚   â”œâ”€ arXiv Search\n",
    "    â”‚   â””â”€ arXiv Fetch\n",
    "    â””â”€ Observation: Process results\n",
    "    â†“\n",
    "Synthesize All Observations â†’ Final Answer\n",
    "```\n",
    "\n",
    "### Citations\n",
    "\n",
    "- **Agentic RAG Survey** (arXiv:2501.09136) - Reference #66\n",
    "- **What is Agentic RAG** | Weaviate - Reference #34\n",
    "- **ReAct: Synergizing Reasoning and Acting in Language Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb289d",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c56532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# LlamaIndex core imports\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core import ToolMetadata\n",
    "\n",
    "# Azure OpenAI imports\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# External tools\n",
    "from duckduckgo_search import DDGS\n",
    "import arxiv\n",
    "\n",
    "# Utilities\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c7f64",
   "metadata": {},
   "source": [
    "## 2. Configure Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Initialize Embedding Model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# Configure global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "print(\"âœ“ Azure OpenAI configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c85ae2",
   "metadata": {},
   "source": [
    "## 3. Create Multiple Knowledge Sources\n",
    "\n",
    "We'll create two distinct knowledge bases:\n",
    "1. **ML Concepts** - Machine learning algorithms and techniques\n",
    "2. **Finance Domain** - Financial concepts and strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML concepts documents\n",
    "ml_data_path = Path(\"../RAG_v2/data/ml_concepts\")\n",
    "ml_documents = SimpleDirectoryReader(str(ml_data_path)).load_data()\n",
    "print(f\"âœ“ Loaded {len(ml_documents)} ML concept documents\")\n",
    "\n",
    "# Parse and index ML documents\n",
    "ml_node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "ml_nodes = ml_node_parser.get_nodes_from_documents(ml_documents)\n",
    "ml_index = VectorStoreIndex(nodes=ml_nodes, embed_model=embed_model)\n",
    "print(f\"âœ“ Created ML knowledge index with {len(ml_nodes)} chunks\")\n",
    "\n",
    "# Load finance documents\n",
    "finance_data_path = Path(\"../RAG_v2/data/finance_docs\")\n",
    "finance_documents = SimpleDirectoryReader(str(finance_data_path)).load_data()\n",
    "print(f\"âœ“ Loaded {len(finance_documents)} finance documents\")\n",
    "\n",
    "# Parse and index finance documents\n",
    "finance_node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "finance_nodes = finance_node_parser.get_nodes_from_documents(finance_documents)\n",
    "finance_index = VectorStoreIndex(nodes=finance_nodes, embed_model=embed_model)\n",
    "print(f\"âœ“ Created finance knowledge index with {len(finance_nodes)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22901b26",
   "metadata": {},
   "source": [
    "## 4. Define Knowledge Base Tools\n",
    "\n",
    "Create query engine tools for each knowledge base with clear descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ML knowledge tool\n",
    "ml_tool = QueryEngineTool(\n",
    "    query_engine=ml_index.as_query_engine(similarity_top_k=3, llm=llm),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"ml_knowledge\",\n",
    "        description=(\n",
    "            \"Expert knowledge about machine learning algorithms, concepts, and techniques. \"\n",
    "            \"Contains information about neural networks, gradient boosting, random forests, \"\n",
    "            \"support vector machines, K-means clustering, and other ML fundamentals. \"\n",
    "            \"Use this for questions about ML theory, algorithms, and implementations.\"\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create finance knowledge tool\n",
    "finance_tool = QueryEngineTool(\n",
    "    query_engine=finance_index.as_query_engine(similarity_top_k=3, llm=llm),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"finance_knowledge\",\n",
    "        description=(\n",
    "            \"Information about financial products, market analysis, portfolio strategies, \"\n",
    "            \"and investment management. Contains knowledge about portfolio diversification, \"\n",
    "            \"risk management, quantitative trading, and reinforcement learning in finance. \"\n",
    "            \"Use this for questions about financial concepts and strategies.\"\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"âœ“ Knowledge base tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bb71e",
   "metadata": {},
   "source": [
    "## 5. Define Internet Search Tool\n",
    "\n",
    "DuckDuckGo search for current information not in our knowledge bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Search the internet for current information using DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "    \n",
    "    Returns:\n",
    "        Formatted search results with titles, URLs, and snippets\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ddgs = DDGS()\n",
    "        results = ddgs.text(query, max_results=5)\n",
    "        \n",
    "        if not results:\n",
    "            return \"No search results found.\"\n",
    "        \n",
    "        formatted_results = \"\\n\\n\".join([\n",
    "            f\"Title: {r['title']}\\nURL: {r['href']}\\nSnippet: {r['body']}\"\n",
    "            for r in results\n",
    "        ])\n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Search failed: {str(e)}\"\n",
    "\n",
    "internet_tool = FunctionTool.from_defaults(\n",
    "    fn=internet_search,\n",
    "    name=\"internet_search\",\n",
    "    description=(\n",
    "        \"Search the internet for current information, news, and real-time data using DuckDuckGo. \"\n",
    "        \"Use this tool for queries about recent events, current trends, latest developments, \"\n",
    "        \"or any information not found in the internal knowledge bases. \"\n",
    "        \"Returns web search results with titles, URLs, and content snippets.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Test the tool\n",
    "test_result = internet_search(\"latest AI news\")\n",
    "print(\"âœ“ Internet search tool created\")\n",
    "print(f\"\\nTest search result (truncated):\\n{test_result[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa7d29",
   "metadata": {},
   "source": [
    "## 6. Define arXiv Search Tool\n",
    "\n",
    "Search academic papers on arXiv for research-related queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b15a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"Search arXiv for academic papers related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query (e.g., \"retrieval augmented generation\")\n",
    "        max_results: Maximum number of papers to return (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted list of papers with titles, authors, IDs, and summaries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for paper in search.results():\n",
    "            arxiv_id = paper.entry_id.split('/')[-1]\n",
    "            results.append(\n",
    "                f\"Title: {paper.title}\\n\"\n",
    "                f\"Authors: {', '.join([a.name for a in paper.authors[:3]])}\" +\n",
    "                (\" et al.\" if len(paper.authors) > 3 else \"\") + \"\\n\"\n",
    "                f\"Published: {paper.published.strftime('%Y-%m-%d')}\\n\"\n",
    "                f\"arXiv ID: {arxiv_id}\\n\"\n",
    "                f\"Summary: {paper.summary[:300]}...\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n---\\n\".join(results) if results else \"No papers found.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"arXiv search failed: {str(e)}\"\n",
    "\n",
    "arxiv_search_tool = FunctionTool.from_defaults(\n",
    "    fn=arxiv_search,\n",
    "    name=\"arxiv_search\",\n",
    "    description=(\n",
    "        \"Search arXiv for academic papers and research publications. \"\n",
    "        \"Returns paper titles, authors, arXiv IDs, publication dates, and summaries. \"\n",
    "        \"Use this for finding recent research papers, academic literature, \"\n",
    "        \"and scientific publications on ML, AI, and related topics. \"\n",
    "        \"The arXiv IDs can be used with arxiv_fetch to get more details.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"âœ“ arXiv search tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77bc3b6",
   "metadata": {},
   "source": [
    "## 7. Define arXiv Fetch Tool\n",
    "\n",
    "Fetch detailed information about a specific paper using its arXiv ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae56db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_fetch(arxiv_id: str) -> str:\n",
    "    \"\"\"Fetch full details of a specific arXiv paper by its ID.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: The arXiv identifier (e.g., '2301.12345' or '2301.12345v1')\n",
    "    \n",
    "    Returns:\n",
    "        Detailed paper information including full abstract\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the ID (remove version if present)\n",
    "        arxiv_id = arxiv_id.split('v')[0] if 'v' in arxiv_id else arxiv_id\n",
    "        \n",
    "        search = arxiv.Search(id_list=[arxiv_id])\n",
    "        paper = next(search.results())\n",
    "        \n",
    "        return (\n",
    "            f\"Title: {paper.title}\\n\"\n",
    "            f\"Authors: {', '.join([a.name for a in paper.authors])}\\n\"\n",
    "            f\"Published: {paper.published.strftime('%Y-%m-%d')}\\n\"\n",
    "            f\"Updated: {paper.updated.strftime('%Y-%m-%d')}\\n\"\n",
    "            f\"arXiv ID: {paper.entry_id.split('/')[-1]}\\n\"\n",
    "            f\"PDF URL: {paper.pdf_url}\\n\"\n",
    "            f\"Categories: {', '.join(paper.categories)}\\n\\n\"\n",
    "            f\"Abstract:\\n{paper.summary}\\n\"\n",
    "        )\n",
    "        \n",
    "    except StopIteration:\n",
    "        return f\"Paper with arXiv ID '{arxiv_id}' not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to fetch paper: {str(e)}\"\n",
    "\n",
    "arxiv_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=arxiv_fetch,\n",
    "    name=\"arxiv_fetch\",\n",
    "    description=(\n",
    "        \"Fetch full details and complete abstract of a specific arXiv paper using its arXiv ID. \"\n",
    "        \"Use this after arxiv_search to get detailed information about a specific paper. \"\n",
    "        \"Provide the arXiv ID (e.g., '2301.12345') to get the full abstract, authors, \"\n",
    "        \"publication date, categories, and PDF URL.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"âœ“ arXiv fetch tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b414c7",
   "metadata": {},
   "source": [
    "## 8. Create ReAct Agent\n",
    "\n",
    "Initialize the agent with all available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baea0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "all_tools = [\n",
    "    ml_tool,\n",
    "    finance_tool,\n",
    "    internet_tool,\n",
    "    arxiv_search_tool,\n",
    "    arxiv_fetch_tool,\n",
    "]\n",
    "\n",
    "# Create ReAct agent\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=all_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=10,  # Increased for complex multi-step queries\n",
    ")\n",
    "\n",
    "print(\"âœ“ ReAct Agent initialized with 5 tools:\")\n",
    "print(\"  1. ml_knowledge - ML concepts and algorithms\")\n",
    "print(\"  2. finance_knowledge - Financial strategies and concepts\")\n",
    "print(\"  3. internet_search - Current web information\")\n",
    "print(\"  4. arxiv_search - Academic paper search\")\n",
    "print(\"  5. arxiv_fetch - Detailed paper retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066ca30",
   "metadata": {},
   "source": [
    "## 9. Test Case 1: Simple Single-Domain Query\n",
    "\n",
    "Agent should identify and use the correct single tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"Explain how gradient boosting works and its main advantages.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 1: {query_1}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should use ml_knowledge tool\\n\")\n",
    "\n",
    "response_1 = agent.chat(query_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_1.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bc7b7",
   "metadata": {},
   "source": [
    "## 10. Test Case 2: Cross-Domain Query\n",
    "\n",
    "Agent should use multiple knowledge bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"How can machine learning algorithms be applied to portfolio optimization and risk management in finance?\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 2: {query_2}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should use both ml_knowledge AND finance_knowledge tools\\n\")\n",
    "\n",
    "response_2 = agent.chat(query_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_2.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff96e6",
   "metadata": {},
   "source": [
    "## 11. Test Case 3: Current Information Query\n",
    "\n",
    "Agent should recognize the need for current data and use internet search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = \"What are the latest developments in large language models as of 2025?\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 3: {query_3}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should use internet_search for current information\\n\")\n",
    "\n",
    "response_3 = agent.chat(query_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_3.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf6842",
   "metadata": {},
   "source": [
    "## 12. Test Case 4: Academic Research Query\n",
    "\n",
    "Agent should use arXiv search and fetch tools for research papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4 = \"Find recent papers on retrieval-augmented generation and summarize their key findings.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 4: {query_4}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should use arxiv_search and possibly arxiv_fetch\\n\")\n",
    "\n",
    "response_4 = agent.chat(query_4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_4.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7bd17",
   "metadata": {},
   "source": [
    "## 13. Test Case 5: Complex Multi-Hop Research Query\n",
    "\n",
    "The most challenging test - requires synthesizing multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_5 = (\n",
    "    \"Compare the effectiveness of reinforcement learning approaches in portfolio management. \"\n",
    "    \"What does our knowledge base say about RL in finance, and are there recent research papers \"\n",
    "    \"on this topic? Provide a comprehensive analysis.\"\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 5: {query_5}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should:\")\n",
    "print(\"  1. Query finance_knowledge for RL in portfolio management\")\n",
    "print(\"  2. Query ml_knowledge for RL fundamentals\")\n",
    "print(\"  3. Use arxiv_search to find recent papers\")\n",
    "print(\"  4. Synthesize all information\\n\")\n",
    "\n",
    "response_5 = agent.chat(query_5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_5.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504909a6",
   "metadata": {},
   "source": [
    "## 14. Test Case 6: Advanced Research with Transformer Comparison\n",
    "\n",
    "Complex query requiring both internal knowledge and external research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_6 = (\n",
    "    \"What are the latest breakthroughs in transformer architectures according to recent arXiv papers, \"\n",
    "    \"and how do they relate to the fundamental concepts in our ML knowledge base?\"\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query 6: {query_6}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected: Agent should:\")\n",
    "print(\"  1. Use arxiv_search for recent transformer papers\")\n",
    "print(\"  2. Use arxiv_fetch for detailed abstracts\")\n",
    "print(\"  3. Query ml_knowledge for transformer fundamentals\")\n",
    "print(\"  4. Compare and synthesize findings\\n\")\n",
    "\n",
    "response_6 = agent.chat(query_6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(response_6.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc92d69",
   "metadata": {},
   "source": [
    "## 15. Compare with Static RAG\n",
    "\n",
    "Demonstrate how static RAG fails on complex multi-source queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10267b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a static RAG baseline (single knowledge base)\n",
    "static_engine = ml_index.as_query_engine(similarity_top_k=5, llm=llm)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: Agentic RAG vs. Static RAG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use the cross-domain query\n",
    "test_query = query_2\n",
    "\n",
    "print(f\"\\nQuery: {test_query}\")\n",
    "print(\"\\n--- Static RAG (ML KB only) ---\")\n",
    "static_response = static_engine.query(test_query)\n",
    "print(static_response.response)\n",
    "\n",
    "print(\"\\n--- Agentic RAG (Multiple Tools) ---\")\n",
    "print(response_2.response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” Key Differences:\")\n",
    "print(\"=\"*80)\n",
    "print(\"Static RAG:\")\n",
    "print(\"  - Limited to single knowledge base (ML only)\")\n",
    "print(\"  - Cannot access finance knowledge or external sources\")\n",
    "print(\"  - Provides incomplete answer\")\n",
    "print(\"\\nAgentic RAG:\")\n",
    "print(\"  - Dynamically selects relevant tools (ML + Finance)\")\n",
    "print(\"  - Can incorporate external sources (web, arXiv)\")\n",
    "print(\"  - Provides comprehensive, multi-faceted answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05255d99",
   "metadata": {},
   "source": [
    "## 16. Analyze Agent Reasoning Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary of agent decisions\n",
    "query_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Query Type\": \"Single Domain\",\n",
    "        \"Query\": query_1[:50] + \"...\",\n",
    "        \"Expected Tools\": \"ml_knowledge\",\n",
    "        \"Complexity\": \"Low\",\n",
    "    },\n",
    "    {\n",
    "        \"Query Type\": \"Cross-Domain\",\n",
    "        \"Query\": query_2[:50] + \"...\",\n",
    "        \"Expected Tools\": \"ml_knowledge, finance_knowledge\",\n",
    "        \"Complexity\": \"Medium\",\n",
    "    },\n",
    "    {\n",
    "        \"Query Type\": \"Current Info\",\n",
    "        \"Query\": query_3[:50] + \"...\",\n",
    "        \"Expected Tools\": \"internet_search\",\n",
    "        \"Complexity\": \"Medium\",\n",
    "    },\n",
    "    {\n",
    "        \"Query Type\": \"Academic Research\",\n",
    "        \"Query\": query_4[:50] + \"...\",\n",
    "        \"Expected Tools\": \"arxiv_search, arxiv_fetch\",\n",
    "        \"Complexity\": \"High\",\n",
    "    },\n",
    "    {\n",
    "        \"Query Type\": \"Multi-Hop\",\n",
    "        \"Query\": query_5[:50] + \"...\",\n",
    "        \"Expected Tools\": \"finance_knowledge, ml_knowledge, arxiv_search\",\n",
    "        \"Complexity\": \"Very High\",\n",
    "    },\n",
    "    {\n",
    "        \"Query Type\": \"Research Synthesis\",\n",
    "        \"Query\": query_6[:50] + \"...\",\n",
    "        \"Expected Tools\": \"arxiv_search, arxiv_fetch, ml_knowledge\",\n",
    "        \"Complexity\": \"Very High\",\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\nAgent Query Analysis Summary\")\n",
    "print(\"=\"*80)\n",
    "print(query_summary.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962ca29",
   "metadata": {},
   "source": [
    "## 17. Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Dynamic Tool Selection**: The agent intelligently chooses the right tool(s) for each query without hardcoded rules.\n",
    "\n",
    "2. **Multi-Step Reasoning**: Complex queries are automatically decomposed into sub-tasks:\n",
    "   - Thought: \"I need information about X\"\n",
    "   - Action: Select and execute tool\n",
    "   - Observation: Process results\n",
    "   - Repeat until complete\n",
    "\n",
    "3. **Tool Orchestration**: The agent can coordinate multiple tools in a single query:\n",
    "   - Internal knowledge bases (ML, Finance)\n",
    "   - External web search (DuckDuckGo)\n",
    "   - Academic databases (arXiv)\n",
    "\n",
    "4. **Adaptability**: Unlike static RAG, agentic RAG adapts to:\n",
    "   - Query complexity\n",
    "   - Information availability\n",
    "   - Required knowledge sources\n",
    "\n",
    "### The ReAct Pattern\n",
    "\n",
    "```\n",
    "Reasoning Trace Example:\n",
    "\n",
    "Thought: \"I need to find ML techniques used in finance\"\n",
    "Action: Query ml_knowledge(\"reinforcement learning basics\")\n",
    "Observation: [ML fundamentals retrieved]\n",
    "\n",
    "Thought: \"Now I need financial context\"\n",
    "Action: Query finance_knowledge(\"RL in portfolio management\")\n",
    "Observation: [Finance applications retrieved]\n",
    "\n",
    "Thought: \"Let me check recent research\"\n",
    "Action: arxiv_search(\"reinforcement learning finance\")\n",
    "Observation: [Recent papers found]\n",
    "\n",
    "Thought: \"I have sufficient information to answer\"\n",
    "Final Answer: [Synthesized response]\n",
    "```\n",
    "\n",
    "### When to Use Agentic RAG\n",
    "\n",
    "- **Complex Information Needs**: Multi-hop questions requiring synthesis\n",
    "- **Multiple Data Sources**: When information is distributed across domains\n",
    "- **Dynamic Requirements**: When you can't predict which sources are needed\n",
    "- **Research Tasks**: Literature review, trend analysis, comparative studies\n",
    "- **Current + Historical**: Combining static KB with real-time data\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "**Advantages**:\n",
    "- Maximum flexibility and adaptability\n",
    "- Can handle unpredictable queries\n",
    "- Comprehensive answers from multiple sources\n",
    "- Transparent reasoning process (when verbose)\n",
    "\n",
    "**Disadvantages**:\n",
    "- Higher latency (multiple LLM calls)\n",
    "- Increased cost (reasoning + tool execution)\n",
    "- Potential for reasoning errors\n",
    "- Complexity in debugging\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "1. **Tool Design**: Clear, unambiguous tool descriptions are critical\n",
    "2. **Error Handling**: Tools must gracefully handle failures\n",
    "3. **Rate Limiting**: External APIs need proper throttling\n",
    "4. **Caching**: Cache tool results for repeated queries\n",
    "5. **Monitoring**: Track tool usage, success rates, and latencies\n",
    "6. **Iteration Limits**: Prevent infinite loops with max_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe847b6a",
   "metadata": {},
   "source": [
    "## 18. Architecture Visualization\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      AGENTIC RAG ARCHITECTURE                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                         Complex User Query\n",
    "                                â†“\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   ReAct Agent       â”‚\n",
    "                    â”‚   (GPT-4)           â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â†“                                     â†“\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚  REASONING       â”‚                 â”‚  ACTION          â”‚\n",
    "    â”‚  \"I need X...\"   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  Select Tool     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                  â†“\n",
    "                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                            â†“                     â†“                     â†“\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚ Internal KB  â”‚    â”‚ External API â”‚    â”‚ Search Tools â”‚\n",
    "                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "                    â”‚ ml_knowledge â”‚    â”‚ arxiv_search â”‚    â”‚ internet_    â”‚\n",
    "                    â”‚ finance_kb   â”‚    â”‚ arxiv_fetch  â”‚    â”‚   search     â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†“                     â†“                     â†“\n",
    "                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                  â†“\n",
    "                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                       â”‚  OBSERVATION     â”‚\n",
    "                                       â”‚  Process Results â”‚\n",
    "                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                  â†“\n",
    "                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                       â”‚  Sufficient?     â”‚\n",
    "                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                          â†“           â†“\n",
    "                                         No          Yes\n",
    "                                          â†“           â†“\n",
    "                                    [Loop Back]   Final Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c56eb",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. **Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG** - arXiv:2501.09136\n",
    "   - Comprehensive survey on agentic design patterns and architectures\n",
    "   - Reference #66 in workshop curriculum\n",
    "\n",
    "2. **ReAct: Synergizing Reasoning and Acting in Language Models** - Yao et al., 2022\n",
    "   - Original paper introducing the ReAct pattern\n",
    "   - Thought-Action-Observation framework\n",
    "\n",
    "3. **What is Agentic RAG** | Weaviate - Reference #34\n",
    "   - Industry perspective on agentic RAG implementations\n",
    "\n",
    "4. **GFM-RAG: Graph Foundation Model for RAG** - arXiv:2502.01113\n",
    "   - Advanced graph-based knowledge integration\n",
    "\n",
    "5. **BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge** - arXiv:2406.19820\n",
    "   - Multi-source knowledge integration techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
