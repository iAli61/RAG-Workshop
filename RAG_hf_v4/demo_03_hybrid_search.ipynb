{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9274b8",
   "metadata": {},
   "source": [
    "# Demo #3: Hybrid Search - Combining Semantic and Keyword Retrieval\n",
    "\n",
    "## Overview\n",
    "\n",
    "This demo demonstrates how **Hybrid Search** combines the strengths of both dense vector search (semantic) and sparse keyword-based retrieval (BM25) to improve retrieval precision across diverse query types.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Dense Vector Search (Semantic)**: Uses embeddings to find semantically similar documents. Great for conceptual queries.\n",
    "2. **BM25 (Sparse/Keyword)**: Traditional keyword matching with TF-IDF weighting. Excels at exact term matches.\n",
    "3. **Reciprocal Rank Fusion (RRF)**: Merges ranked results from multiple retrievers by combining their reciprocal ranks.\n",
    "\n",
    "### Why Hybrid Search?\n",
    "\n",
    "- **Semantic search** may miss documents with exact technical terms if they're not semantically close\n",
    "- **Keyword search** fails on conceptual queries where terms don't match exactly\n",
    "- **Hybrid approach** gets the best of both worlds\n",
    "\n",
    "### Citations\n",
    "\n",
    "- **Hybrid Search Technique**: \"What is Retrieval-Augmented Generation (RAG)? | Google Cloud\"\n",
    "- **RRF Algorithm**: \"Using Hybrid Search to Deliver Fast and Contextually Relevant Results\" (Ragie)\n",
    "- **Best Practices**: \"Advanced RAG Implementation using Hybrid Search and Reranking\" (Medium)\n",
    "\n",
    "### Recommended Hugging Face Resources\n",
    "\n",
    "- **BAAI/bge-m3**: Native support for dense, sparse, and hybrid search - [Link](https://hf.co/BAAI/bge-m3)\n",
    "- **Paper**: \"Vietnamese Legal Information Retrieval\" - RRF implementation example - [Link](https://hf.co/papers/2409.13699)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b27c4",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q llama-index llama-index-llms-azure-openai llama-index-embeddings-azure-openai\n",
    "!pip install -q llama-index-retrievers-bm25 rank-bm25\n",
    "!pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84949bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LlamaIndex core imports\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# Azure OpenAI imports\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# BM25 retriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# For visualization\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81171db",
   "metadata": {},
   "source": [
    "## Configure Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI LLM\n",
    "azure_llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\"),\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Initialize Azure OpenAI Embedding Model\n",
    "azure_embed = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\"),\n",
    ")\n",
    "\n",
    "# Set global defaults\n",
    "Settings.llm = azure_llm\n",
    "Settings.embed_model = azure_embed\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "print(\"âœ“ Azure OpenAI configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b68885",
   "metadata": {},
   "source": [
    "## Load and Chunk Technical Documents\n",
    "\n",
    "We'll use technical documents that contain:\n",
    "- Specific technical terms and acronyms (BERT, GPT-4, API, Docker)\n",
    "- Conceptual information about how these technologies work\n",
    "\n",
    "This mix is perfect for testing hybrid search effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from tech_docs directory\n",
    "# Adjust path based on your project structure\n",
    "data_path = \"../RAG_v2/data/tech_docs\"\n",
    "\n",
    "documents = SimpleDirectoryReader(data_path).load_data()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents:\")\n",
    "for doc in documents:\n",
    "    filename = doc.metadata.get('file_name', 'Unknown')\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse documents into chunks\n",
    "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "print(f\"\\nâœ“ Created {len(nodes)} text chunks\")\n",
    "print(f\"\\nExample chunk:\")\n",
    "print(\"=\" * 80)\n",
    "print(nodes[0].get_content()[:300] + \"...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220dfe53",
   "metadata": {},
   "source": [
    "## Approach #1: Pure Semantic Search (Baseline)\n",
    "\n",
    "Build a standard vector index using only dense embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index\n",
    "vector_index = VectorStoreIndex(nodes, embed_model=azure_embed)\n",
    "\n",
    "# Create vector-only retriever\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Create query engine\n",
    "vector_engine = RetrieverQueryEngine(\n",
    "    retriever=vector_retriever,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "print(\"âœ“ Vector search baseline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9b5c5",
   "metadata": {},
   "source": [
    "## Approach #2: BM25 Keyword Search\n",
    "\n",
    "Traditional sparse retrieval using keyword matching and TF-IDF scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5\n",
    ")\n",
    "\n",
    "# Create query engine\n",
    "bm25_engine = RetrieverQueryEngine(\n",
    "    retriever=bm25_retriever,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "print(\"âœ“ BM25 keyword search ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a8d94",
   "metadata": {},
   "source": [
    "## Approach #3: Hybrid Search with Reciprocal Rank Fusion\n",
    "\n",
    "Combine both retrievers using QueryFusionRetriever with RRF merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid retriever with Reciprocal Rank Fusion\n",
    "hybrid_retriever = QueryFusionRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=5,\n",
    "    num_queries=1,  # Use original query only (no query generation)\n",
    "    mode=\"reciprocal_rerank\",  # RRF merging strategy\n",
    "    use_async=False\n",
    ")\n",
    "\n",
    "# Create query engine\n",
    "hybrid_engine = RetrieverQueryEngine(\n",
    "    retriever=hybrid_retriever,\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "print(\"âœ“ Hybrid search with RRF ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2c2bc",
   "metadata": {},
   "source": [
    "## Test Query #1: Exact Term Match (\"What is BERT?\")\n",
    "\n",
    "This query requires finding the specific acronym \"BERT\" in the documents.\n",
    "- **Expected**: BM25 should excel due to exact keyword matching\n",
    "- **Challenge**: Semantic search might return related but not exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"What is BERT?\"\n",
    "\n",
    "print(f\"Query: {query1}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test all three approaches\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "vector_nodes = vector_retriever.retrieve(query1)\n",
    "for i, node in enumerate(vector_nodes, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_nodes = bm25_retriever.retrieve(query1)\n",
    "for i, node in enumerate(bm25_nodes, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH RESULTS (RRF):\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_nodes = hybrid_retriever.retrieve(query1)\n",
    "for i, node in enumerate(hybrid_nodes, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c6967",
   "metadata": {},
   "source": [
    "### Generate Final Answers for Query #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf90ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL ANSWERS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "vector_response = vector_engine.query(query1)\n",
    "print(vector_response.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_response = bm25_engine.query(query1)\n",
    "print(bm25_response.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_response = hybrid_engine.query(query1)\n",
    "print(hybrid_response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a12f67",
   "metadata": {},
   "source": [
    "## Test Query #2: Conceptual Query (\"How do transformer models work?\")\n",
    "\n",
    "This query requires semantic understanding, not just keyword matching.\n",
    "- **Expected**: Semantic search should excel\n",
    "- **Challenge**: BM25 needs exact word matches for \"transformer\", \"models\", \"work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"How do transformer models work?\"\n",
    "\n",
    "print(f\"Query: {query2}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test all three approaches\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "vector_nodes_q2 = vector_retriever.retrieve(query2)\n",
    "for i, node in enumerate(vector_nodes_q2, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_nodes_q2 = bm25_retriever.retrieve(query2)\n",
    "for i, node in enumerate(bm25_nodes_q2, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH RESULTS (RRF):\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_nodes_q2 = hybrid_retriever.retrieve(query2)\n",
    "for i, node in enumerate(hybrid_nodes_q2, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8b6cb",
   "metadata": {},
   "source": [
    "### Generate Final Answers for Query #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e579b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL ANSWERS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "vector_response_q2 = vector_engine.query(query2)\n",
    "print(vector_response_q2.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_response_q2 = bm25_engine.query(query2)\n",
    "print(bm25_response_q2.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_response_q2 = hybrid_engine.query(query2)\n",
    "print(hybrid_response_q2.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b95bae",
   "metadata": {},
   "source": [
    "## Test Query #3: Mixed Query (\"What are Docker containers used for in API development?\")\n",
    "\n",
    "This query combines specific technical terms (Docker, API) with conceptual understanding (usage, purpose).\n",
    "- **Expected**: Hybrid search should excel by leveraging both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e57823",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"What are Docker containers used for in API development?\"\n",
    "\n",
    "print(f\"Query: {query3}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test all three approaches\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "vector_nodes_q3 = vector_retriever.retrieve(query3)\n",
    "for i, node in enumerate(vector_nodes_q3, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_nodes_q3 = bm25_retriever.retrieve(query3)\n",
    "for i, node in enumerate(bm25_nodes_q3, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH RESULTS (RRF):\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_nodes_q3 = hybrid_retriever.retrieve(query3)\n",
    "for i, node in enumerate(hybrid_nodes_q3, 1):\n",
    "    print(f\"\\nRank {i} (Score: {node.score:.4f}):\")\n",
    "    print(f\"Source: {node.node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"Text: {node.node.get_content()[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420f626",
   "metadata": {},
   "source": [
    "### Generate Final Answers for Query #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ade703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL ANSWERS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ”µ SEMANTIC SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "vector_response_q3 = vector_engine.query(query3)\n",
    "print(vector_response_q3.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ¢ BM25 KEYWORD SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "bm25_response_q3 = bm25_engine.query(query3)\n",
    "print(bm25_response_q3.response)\n",
    "\n",
    "print(\"\\n\\nðŸŸ£ HYBRID SEARCH ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "hybrid_response_q3 = hybrid_engine.query(query3)\n",
    "print(hybrid_response_q3.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fcab2",
   "metadata": {},
   "source": [
    "## Understanding Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "### How RRF Works\n",
    "\n",
    "RRF merges rankings from multiple retrievers using the formula:\n",
    "\n",
    "$$\\text{RRF Score} = \\sum_{r \\in \\text{retrievers}} \\frac{1}{k + \\text{rank}_r(d)}$$\n",
    "\n",
    "Where:\n",
    "- $k$ is a constant (typically 60)\n",
    "- $\\text{rank}_r(d)$ is the rank of document $d$ in retriever $r$\n",
    "- Documents not retrieved by a retriever get a rank of infinity (contributing 0 to the sum)\n",
    "\n",
    "### Why RRF is Effective\n",
    "\n",
    "1. **Score Normalization**: Works without needing to normalize different scoring schemes (cosine similarity vs. BM25 scores)\n",
    "2. **Rank-Based**: Focuses on relative ranking rather than absolute scores\n",
    "3. **Simple & Robust**: No hyperparameters to tune beyond $k$\n",
    "\n",
    "### Example\n",
    "\n",
    "If a document is ranked:\n",
    "- **#1 in semantic search**: contributes $\\frac{1}{60+1} = 0.0164$\n",
    "- **#3 in BM25**: contributes $\\frac{1}{60+3} = 0.0159$\n",
    "- **Total RRF Score**: $0.0164 + 0.0159 = 0.0323$\n",
    "\n",
    "A document highly ranked in both gets a high combined score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3841e2",
   "metadata": {},
   "source": [
    "## Data Flow Visualization\n",
    "\n",
    "```\n",
    "Query: \"What is BERT?\"\n",
    "         |\n",
    "         v\n",
    "    [Split to both retrievers]\n",
    "         |\n",
    "    +-----------+-----------+\n",
    "    |                       |\n",
    "    v                       v\n",
    "[Vector Search]      [BM25 Search]\n",
    "(Semantic)           (Keyword)\n",
    "    |                       |\n",
    "    v                       v\n",
    "Ranked List 1        Ranked List 2\n",
    "1. Doc A (0.89)      1. Doc B (12.4)\n",
    "2. Doc C (0.85)      2. Doc A (11.2)\n",
    "3. Doc B (0.82)      3. Doc D (10.8)\n",
    "4. Doc D (0.78)      4. Doc C (9.5)\n",
    "5. Doc E (0.75)      5. Doc F (8.9)\n",
    "    |                       |\n",
    "    +----------+------------+\n",
    "               |\n",
    "               v\n",
    "    [Reciprocal Rank Fusion]\n",
    "    Calculate: 1/(k+rank) for each doc\n",
    "               |\n",
    "               v\n",
    "      Unified Ranked List\n",
    "      1. Doc A (best in both)\n",
    "      2. Doc B (high in both)\n",
    "      3. Doc C (medium)\n",
    "      4. Doc D (medium)\n",
    "      5. Doc E (lower)\n",
    "               |\n",
    "               v\n",
    "         [LLM Generation]\n",
    "               |\n",
    "               v\n",
    "         Final Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a59c16",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Let's create a comparison table to visualize when each approach excels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = {\n",
    "    'Query Type': ['Exact Term Match', 'Conceptual Query', 'Mixed Query'],\n",
    "    'Example': [\n",
    "        'What is BERT?',\n",
    "        'How do transformer models work?',\n",
    "        'What are Docker containers used for in API development?'\n",
    "    ],\n",
    "    'Best Approach': ['BM25 / Hybrid', 'Semantic / Hybrid', 'Hybrid'],\n",
    "    'Why': [\n",
    "        'Exact keyword \"BERT\" needs to be matched',\n",
    "        'Requires semantic understanding of concepts',\n",
    "        'Benefits from both term matching and semantic understanding'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"WHEN TO USE EACH APPROACH\")\n",
    "print(\"=\" * 100)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e42e5",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Strengths of Each Approach\n",
    "\n",
    "#### ðŸ”µ Semantic Search (Dense Vectors)\n",
    "- **Best for**: Conceptual queries, paraphrasing, synonyms\n",
    "- **Strength**: Understands meaning beyond exact words\n",
    "- **Weakness**: May miss exact technical terms or acronyms\n",
    "\n",
    "#### ðŸŸ¢ BM25 (Sparse/Keyword)\n",
    "- **Best for**: Exact term matches, technical terminology, proper nouns\n",
    "- **Strength**: Reliable for finding specific words/phrases\n",
    "- **Weakness**: No semantic understanding, fails on paraphrasing\n",
    "\n",
    "#### ðŸŸ£ Hybrid Search (RRF)\n",
    "- **Best for**: Production systems with diverse query types\n",
    "- **Strength**: Combines benefits of both, robust across query types\n",
    "- **Weakness**: Slightly more complex, requires both retrievers\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Start with Hybrid**: Unless you have a very specific use case, hybrid search provides the most robust solution\n",
    "2. **Adjust top_k**: For hybrid, retrieve more from each (e.g., 10-20) before fusion to get diverse candidates\n",
    "3. **Monitor Query Patterns**: Analyze your actual queries to see which approach works best\n",
    "4. **Consider Re-ranking**: Hybrid search can be combined with re-ranking for even better precision (see Demo #5)\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **Latency**: Hybrid search is roughly 2x the cost of single retriever (runs both in parallel)\n",
    "- **Index Size**: Need both vector index and BM25 index\n",
    "- **Updates**: Both indices need updating when documents change\n",
    "- **Scalability**: Vector search scales better than BM25 for very large corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4d578",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Hybrid search with Reciprocal Rank Fusion provides a robust retrieval strategy that:\n",
    "1. Handles both exact-match and semantic queries effectively\n",
    "2. Requires no complex score normalization\n",
    "3. Is simple to implement with QueryFusionRetriever\n",
    "4. Provides consistently good performance across diverse query types\n",
    "\n",
    "**Next Steps**: Combine hybrid search with re-ranking (Demo #5) for even better precision!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
